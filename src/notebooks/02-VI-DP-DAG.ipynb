{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 4 CUDA device(s).\n",
      "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n"
     ]
    }
   ],
   "source": [
    "from src.probabilistic_dag_model.probabilistic_dag_autoencoder import ProbabilisticDAGAutoencoder\n",
    "from src.probabilistic_dag_model.train_probabilistic_dag_autoencoder import train_autoencoder\n",
    "from src.datasets.DAGDataset import get_dag_dataset\n",
    "from src.run_probabilistic_dag_autoencoder import run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG & Causal mechanisms learning from observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'seed_dataset': 123,  # Seed to shuffle dataset. int\n",
    "    'dataset_name': 'data_p10_e10_n1000_GP',  # Dataset name. string\n",
    "    'dataset_directory': 'TO COMPLETE', # Dataset directory. string\n",
    "    'i_dataset': 1,  # Dataset name. string\n",
    "    'split': [.8, .1, .1],  # Split for train/val/test sets. list of floats\n",
    "\n",
    "    # Architecture parameters\n",
    "    'seed_model': 123,  # Seed to init model. int\n",
    "    'directory_model': 'TO COMPLETE',  # Path to save model. string\n",
    "    'ma_hidden_dims': [16, 16, 16],  # Output dimension. int\n",
    "    'ma_architecture': 'linear',  # Output dimension. int\n",
    "    'ma_fast': False,  # Output dimension. int\n",
    "    'pd_initial_adj': 'Learned',  # Output dimension. int\n",
    "    'pd_temperature': 1.0,  # Output dimension. int\n",
    "    'pd_hard': True,  # Output dimension. int\n",
    "    'pd_order_type': 'topk',  # Output dimension. int\n",
    "    'pd_noise_factor': 1.0,  # Hidden dimensions. list of ints\n",
    "\n",
    "    # Training parameters\n",
    "    'directory_results': 'TO COMPLETE',  # Path to save resutls. string\n",
    "    'max_epochs': 100,  # Maximum number of epochs for training\n",
    "    'patience': 10,  # Patience for early stopping. int\n",
    "    'frequency': 2,  # Frequency for early stopping test. int\n",
    "    'batch_size': 64,  # Batch size. int\n",
    "    'ma_lr': 1e-3,  # Learning rate. float\n",
    "    'pd_lr': 1e-2,  # Learning rate. float\n",
    "    'loss': 'ELBO',  # Loss name. string\n",
    "    'regr': .01,  # Regularization factor in Bayesian loss. float\n",
    "    'prior_p': .01  # Regularization factor in Bayesian loss. float\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:22:41 (INFO): Received the following configuration:\n",
      "2021-10-04 20:22:41 (INFO): DATASET | seed_dataset 123 - dataset_name data_p10_e10_n1000_GP - i_dataset 1 - split [0.8, 0.1, 0.1]\n",
      "2021-10-04 20:22:41 (INFO): ARCHITECTURE |  seed_model 123 -  ma_hidden_dims [16, 16, 16] -  ma_architecture linear -  ma_fast False -  pd_initial_adj Learned -  pd_temperature 1.0 -  pd_hard True -  pd_order_type topk -  pd_noise_factor 1.0\n",
      "2021-10-04 20:22:41 (INFO): TRAINING |  max_epochs 10 -  patience 10 -  frequency 2 -  batch_size 64 -  ma_lr 0.001 -  pd_lr 0.01 -  loss ELBO -  regr 0.01 -  prior_p 0.01\n",
      "reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 0.105 | Val MSE.: 1.047\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 0.102 | Val MSE.: 1.02\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 0.1 | Val MSE.: 0.995\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 0.096 | Val MSE.: 0.961\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 0.091 | Val MSE.: 0.912\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "results = run(**param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '/nfs/staff-hdd/charpent/probabilistic-dag-learning/saved_models/model-autopdag-123-data_p10_e10_n1000_GP-1-[0.8, 0.1, 0.1]-123-[16, 16, 16]-linear-False-Learned-1.0-True-topk-1.0-10-10-2-64-0.001-0.01-ELBO-0.01-0.01',\n",
       " 'result_path': '/nfs/staff-hdd/charpent/probabilistic-dag-learning/saved_results/results-autopdag-123-data_p10_e10_n1000_GP-1-[0.8, 0.1, 0.1]-123-[16, 16, 16]-linear-False-Learned-1.0-True-topk-1.0-10-10-2-64-0.001-0.01-ELBO-0.01-0.01',\n",
       " 'training_time': 9.449467420578003,\n",
       " 'train_losses': [0.101, 0.099, 0.096, 0.093, 0.088],\n",
       " 'val_losses': [0.10491502285003662,\n",
       "  0.10228793621063233,\n",
       "  0.0997266948223114,\n",
       "  0.09636774063110351,\n",
       "  0.09140468835830688],\n",
       " 'train_mse': [1.006, 0.983, 0.959, 0.925, 0.875],\n",
       " 'val_mse': [1.046655297279358,\n",
       "  1.0203872919082642,\n",
       "  0.994779646396637,\n",
       "  0.9611950516700745,\n",
       "  0.9115694165229797],\n",
       " 'fail_trace': <function seml.evaluation.get_results(db_collection_name, fields=None, to_data_frame=False, mongodb_config=None, states=None, filter_dict=None, parallel=False)>,\n",
       " 'undirected_edge_auroc': 0.8869047619047619,\n",
       " 'undirected_edge_apr': 0.7886121553884712,\n",
       " 'reverse_edge_auroc': 0.5964673913043479,\n",
       " 'reverse_edge_apr': 0.29520833333333335,\n",
       " 'edge_auroc': 0.6073369565217391,\n",
       " 'edge_apr': 0.28655388471177945,\n",
       " 'reconstruction': 0.8760283589363098}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
