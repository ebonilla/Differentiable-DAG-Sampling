{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probabilistic_dag_model.probabilistic_dag import ProbabilisticDAG\n",
    "from src.probabilistic_dag_model.train_dag import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sampling time:  0.0016643206278483074\n"
     ]
    }
   ],
   "source": [
    "n_samples = 30\n",
    "sampling_times = np.zeros(n_samples)\n",
    "prob_dag_model = ProbabilisticDAG(n_nodes=100,\n",
    "                                  order_type='topk',\n",
    "                                  #order_type='sinkhorn',\n",
    "                                  initial_adj=None, \n",
    "                                  seed=100)\n",
    "for i in range(n_samples):\n",
    "    t0 = time.time()\n",
    "    A = prob_dag_model.sample().detach().cpu().numpy()\n",
    "    sampling_times[i] = time.time() - t0\n",
    "print('Mean sampling time: ', sampling_times.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG learning with a ground-truth dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "n_nodes=10\n",
    "true_dag_adj = torch.triu(torch.ones(n_nodes, n_nodes, device=device), 1)\n",
    "model = ProbabilisticDAG(n_nodes=n_nodes,\n",
    "                         hard=True,\n",
    "                         #order_type='sinkhorn',\n",
    "                         order_type='topk',\n",
    "                         lr=1e-2,\n",
    "                         seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> prob_abs_loss 0.06914740800857544 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 10 -> prob_abs_loss 0.06894344091415405 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 20 -> prob_abs_loss 0.06835818290710449 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 30 -> prob_abs_loss 0.06802433729171753 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 40 -> prob_abs_loss 0.06790167093276978 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 50 -> prob_abs_loss 0.0678589940071106 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 60 -> prob_abs_loss 0.06750613451004028 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 70 -> prob_abs_loss 0.06730824708938599 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 80 -> prob_abs_loss 0.06708943843841553 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 90 -> prob_abs_loss 0.06689667701721191 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 100 -> prob_abs_loss 0.06656724214553833 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 110 -> prob_abs_loss 0.06631773710250854 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 120 -> prob_abs_loss 0.06621712446212769 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 130 -> prob_abs_loss 0.06600332260131836 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 140 -> prob_abs_loss 0.06581449508666992 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 150 -> prob_abs_loss 0.06553030014038086 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 160 -> prob_abs_loss 0.06518405675888062 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 170 -> prob_abs_loss 0.06493139266967773 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 180 -> prob_abs_loss 0.06456416845321655 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 190 -> prob_abs_loss 0.06420177221298218 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 200 -> prob_abs_loss 0.06382244825363159 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 210 -> prob_abs_loss 0.06335020065307617 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 220 -> prob_abs_loss 0.06301695108413696 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 230 -> prob_abs_loss 0.06279778480529785 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 240 -> prob_abs_loss 0.06265980005264282 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 250 -> prob_abs_loss 0.06252080202102661 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 260 -> prob_abs_loss 0.061974287033081055 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 270 -> prob_abs_loss 0.06173807382583618 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 280 -> prob_abs_loss 0.06162005662918091 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 290 -> prob_abs_loss 0.06149482727050781 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 300 -> prob_abs_loss 0.061282336711883545 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 310 -> prob_abs_loss 0.0611150860786438 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 320 -> prob_abs_loss 0.060970962047576904 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 330 -> prob_abs_loss 0.060902953147888184 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 340 -> prob_abs_loss 0.06077533960342407 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 350 -> prob_abs_loss 0.060709357261657715 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 360 -> prob_abs_loss 0.060634613037109375 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 370 -> prob_abs_loss 0.0605892539024353 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 380 -> prob_abs_loss 0.06040531396865845 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 390 -> prob_abs_loss 0.060170769691467285 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 400 -> prob_abs_loss 0.059973299503326416 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 410 -> prob_abs_loss 0.05975675582885742 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 420 -> prob_abs_loss 0.05956268310546875 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 430 -> prob_abs_loss 0.059137165546417236 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 440 -> prob_abs_loss 0.05884718894958496 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 450 -> prob_abs_loss 0.0586586594581604 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 460 -> prob_abs_loss 0.05859541893005371 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 470 -> prob_abs_loss 0.05857342481613159 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 480 -> prob_abs_loss 0.058315277099609375 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 490 -> prob_abs_loss 0.05817615985870361 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 500 -> prob_abs_loss 0.058055758476257324 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 510 -> prob_abs_loss 0.05781960487365723 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 520 -> prob_abs_loss 0.057742297649383545 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 530 -> prob_abs_loss 0.05771589279174805 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 540 -> prob_abs_loss 0.057660698890686035 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 550 -> prob_abs_loss 0.057536959648132324 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 560 -> prob_abs_loss 0.057386040687561035 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 570 -> prob_abs_loss 0.05717766284942627 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 580 -> prob_abs_loss 0.05701756477355957 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 590 -> prob_abs_loss 0.056959569454193115 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 600 -> prob_abs_loss 0.056755125522613525 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 610 -> prob_abs_loss 0.05662292242050171 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 620 -> prob_abs_loss 0.05647933483123779 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 630 -> prob_abs_loss 0.0563962459564209 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 640 -> prob_abs_loss 0.05636817216873169 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 650 -> prob_abs_loss 0.056358397006988525 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 660 -> prob_abs_loss 0.056308209896087646 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 670 -> prob_abs_loss 0.056013643741607666 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 680 -> prob_abs_loss 0.055826425552368164 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 690 -> prob_abs_loss 0.05568218231201172 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 700 -> prob_abs_loss 0.05562180280685425 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 710 -> prob_abs_loss 0.055600523948669434 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 720 -> prob_abs_loss 0.05559134483337402 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 730 -> prob_abs_loss 0.0555880069732666 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 740 -> prob_abs_loss 0.055535972118377686 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 750 -> prob_abs_loss 0.055403828620910645 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 760 -> prob_abs_loss 0.05536091327667236 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 770 -> prob_abs_loss 0.05534625053405762 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 780 -> prob_abs_loss 0.055341243743896484 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 790 -> prob_abs_loss 0.05531829595565796 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 800 -> prob_abs_loss 0.05519932508468628 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 810 -> prob_abs_loss 0.05509233474731445 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 820 -> prob_abs_loss 0.054849207401275635 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 830 -> prob_abs_loss 0.05475819110870361 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 840 -> prob_abs_loss 0.054727137088775635 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 850 -> prob_abs_loss 0.05460011959075928 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 860 -> prob_abs_loss 0.05422085523605347 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 870 -> prob_abs_loss 0.05390042066574097 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 880 -> prob_abs_loss 0.0537945032119751 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 890 -> prob_abs_loss 0.05375838279724121 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 900 -> prob_abs_loss 0.053745806217193604 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 910 -> prob_abs_loss 0.053741395473480225 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 920 -> prob_abs_loss 0.053739845752716064 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 930 -> prob_abs_loss 0.05373924970626831 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 940 -> prob_abs_loss 0.05373913049697876 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 950 -> prob_abs_loss 0.05373901128768921 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 960 -> prob_abs_loss 0.053655266761779785 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 970 -> prob_abs_loss 0.05358231067657471 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 980 -> prob_abs_loss 0.05355805158615112 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 990 -> prob_abs_loss 0.053408265113830566 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1000 -> prob_abs_loss 0.053327739238739014 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1010 -> prob_abs_loss 0.05330061912536621 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1020 -> prob_abs_loss 0.05309063196182251 | sampled_mse_loss 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Epoch 1030 -> prob_abs_loss 0.05301368236541748 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1040 -> prob_abs_loss 0.05298799276351929 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1050 -> prob_abs_loss 0.0528489351272583 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 1060 -> prob_abs_loss 0.05279666185379028 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1070 -> prob_abs_loss 0.05252760648727417 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1080 -> prob_abs_loss 0.05216771364212036 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1090 -> prob_abs_loss 0.05197864770889282 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1100 -> prob_abs_loss 0.05191540718078613 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1110 -> prob_abs_loss 0.05172300338745117 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1120 -> prob_abs_loss 0.051579415798187256 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 1130 -> prob_abs_loss 0.05153089761734009 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1140 -> prob_abs_loss 0.051514387130737305 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1150 -> prob_abs_loss 0.05150848627090454 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 1160 -> prob_abs_loss 0.05141246318817139 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1170 -> prob_abs_loss 0.05135965347290039 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1180 -> prob_abs_loss 0.051342010498046875 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1190 -> prob_abs_loss 0.05119842290878296 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1200 -> prob_abs_loss 0.050980448722839355 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1210 -> prob_abs_loss 0.05078732967376709 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1220 -> prob_abs_loss 0.05072379112243652 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1230 -> prob_abs_loss 0.05058974027633667 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1240 -> prob_abs_loss 0.05043762922286987 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1250 -> prob_abs_loss 0.050303876399993896 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1260 -> prob_abs_loss 0.04998880624771118 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1270 -> prob_abs_loss 0.04964643716812134 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1280 -> prob_abs_loss 0.049534499645233154 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1290 -> prob_abs_loss 0.049370646476745605 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1300 -> prob_abs_loss 0.04925328493118286 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 1310 -> prob_abs_loss 0.049213409423828125 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1320 -> prob_abs_loss 0.04919874668121338 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1330 -> prob_abs_loss 0.04915958642959595 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1340 -> prob_abs_loss 0.0491185188293457 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1350 -> prob_abs_loss 0.04910445213317871 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1360 -> prob_abs_loss 0.04909956455230713 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1370 -> prob_abs_loss 0.04909801483154297 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1380 -> prob_abs_loss 0.048952341079711914 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1390 -> prob_abs_loss 0.04890543222427368 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1400 -> prob_abs_loss 0.0488201379776001 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 1410 -> prob_abs_loss 0.04870051145553589 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1420 -> prob_abs_loss 0.04862111806869507 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1430 -> prob_abs_loss 0.04840695858001709 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1440 -> prob_abs_loss 0.04830211400985718 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1450 -> prob_abs_loss 0.0482669472694397 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1460 -> prob_abs_loss 0.04825466871261597 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 1470 -> prob_abs_loss 0.04817682504653931 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1480 -> prob_abs_loss 0.04798847436904907 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1490 -> prob_abs_loss 0.04790067672729492 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1500 -> prob_abs_loss 0.04777359962463379 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1510 -> prob_abs_loss 0.047505736351013184 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1520 -> prob_abs_loss 0.04740023612976074 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1530 -> prob_abs_loss 0.04736495018005371 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1540 -> prob_abs_loss 0.04727518558502197 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1550 -> prob_abs_loss 0.04723554849624634 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1560 -> prob_abs_loss 0.0472220778465271 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1570 -> prob_abs_loss 0.04721742868423462 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 1580 -> prob_abs_loss 0.04716229438781738 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1590 -> prob_abs_loss 0.04696851968765259 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1600 -> prob_abs_loss 0.04677236080169678 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 1610 -> prob_abs_loss 0.04659050703048706 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1620 -> prob_abs_loss 0.04647558927536011 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1630 -> prob_abs_loss 0.046245455741882324 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1640 -> prob_abs_loss 0.04614412784576416 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1650 -> prob_abs_loss 0.04584980010986328 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1660 -> prob_abs_loss 0.0455208420753479 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1670 -> prob_abs_loss 0.045304834842681885 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1680 -> prob_abs_loss 0.04523289203643799 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1690 -> prob_abs_loss 0.04520827531814575 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1700 -> prob_abs_loss 0.045178890228271484 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 1710 -> prob_abs_loss 0.04501420259475708 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1720 -> prob_abs_loss 0.04490303993225098 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1730 -> prob_abs_loss 0.04486638307571411 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1740 -> prob_abs_loss 0.04477059841156006 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1750 -> prob_abs_loss 0.04467219114303589 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1760 -> prob_abs_loss 0.04448968172073364 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1770 -> prob_abs_loss 0.04442167282104492 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 1780 -> prob_abs_loss 0.044398605823516846 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 1790 -> prob_abs_loss 0.04439049959182739 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1800 -> prob_abs_loss 0.044387757778167725 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1810 -> prob_abs_loss 0.04424232244491577 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1820 -> prob_abs_loss 0.044145941734313965 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1830 -> prob_abs_loss 0.04411435127258301 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1840 -> prob_abs_loss 0.0440329909324646 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1850 -> prob_abs_loss 0.04391556978225708 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 1860 -> prob_abs_loss 0.043877363204956055 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1870 -> prob_abs_loss 0.04386425018310547 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1880 -> prob_abs_loss 0.043776631355285645 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 1890 -> prob_abs_loss 0.04373723268508911 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 1900 -> prob_abs_loss 0.043724000453948975 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 1910 -> prob_abs_loss 0.043719470500946045 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1920 -> prob_abs_loss 0.043717801570892334 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1930 -> prob_abs_loss 0.04371732473373413 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1940 -> prob_abs_loss 0.04371708631515503 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 1950 -> prob_abs_loss 0.04368466138839722 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1960 -> prob_abs_loss 0.04366612434387207 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1970 -> prob_abs_loss 0.04362297058105469 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 1980 -> prob_abs_loss 0.04338294267654419 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 1990 -> prob_abs_loss 0.043199777603149414 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2000 -> prob_abs_loss 0.04310798645019531 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2010 -> prob_abs_loss 0.043076932430267334 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2020 -> prob_abs_loss 0.04306596517562866 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2030 -> prob_abs_loss 0.04306226968765259 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 2040 -> prob_abs_loss 0.04306095838546753 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2050 -> prob_abs_loss 0.04306060075759888 | sampled_mse_loss 1.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2060 -> prob_abs_loss 0.043060362339019775 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2070 -> prob_abs_loss 0.04280298948287964 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2080 -> prob_abs_loss 0.04244166612625122 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2090 -> prob_abs_loss 0.04221218824386597 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2100 -> prob_abs_loss 0.0421367883682251 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 2110 -> prob_abs_loss 0.04211074113845825 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2120 -> prob_abs_loss 0.042101919651031494 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2130 -> prob_abs_loss 0.04209417104721069 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2140 -> prob_abs_loss 0.0419653058052063 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2150 -> prob_abs_loss 0.04189032316207886 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2160 -> prob_abs_loss 0.041731059551239014 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 2170 -> prob_abs_loss 0.04168045520782471 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 2180 -> prob_abs_loss 0.041663527488708496 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2190 -> prob_abs_loss 0.0416300892829895 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 2200 -> prob_abs_loss 0.0414775013923645 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2210 -> prob_abs_loss 0.04142838716506958 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2220 -> prob_abs_loss 0.041341304779052734 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2230 -> prob_abs_loss 0.041297078132629395 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2240 -> prob_abs_loss 0.04128223657608032 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 2250 -> prob_abs_loss 0.04106175899505615 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2260 -> prob_abs_loss 0.0409160852432251 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2270 -> prob_abs_loss 0.040806472301483154 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2280 -> prob_abs_loss 0.04066646099090576 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2290 -> prob_abs_loss 0.040586233139038086 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 2300 -> prob_abs_loss 0.040559589862823486 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2310 -> prob_abs_loss 0.040550291538238525 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 2320 -> prob_abs_loss 0.040547192096710205 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2330 -> prob_abs_loss 0.0405460000038147 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2340 -> prob_abs_loss 0.040374577045440674 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2350 -> prob_abs_loss 0.0403214693069458 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2360 -> prob_abs_loss 0.04030364751815796 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2370 -> prob_abs_loss 0.04026305675506592 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2380 -> prob_abs_loss 0.04020410776138306 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2390 -> prob_abs_loss 0.04018455743789673 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2400 -> prob_abs_loss 0.040158987045288086 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2410 -> prob_abs_loss 0.0398445725440979 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2420 -> prob_abs_loss 0.03969186544418335 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2430 -> prob_abs_loss 0.03955763578414917 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2440 -> prob_abs_loss 0.03951340913772583 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2450 -> prob_abs_loss 0.03944021463394165 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2460 -> prob_abs_loss 0.03932833671569824 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2470 -> prob_abs_loss 0.039225220680236816 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2480 -> prob_abs_loss 0.03919142484664917 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2490 -> prob_abs_loss 0.03911620378494263 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 2500 -> prob_abs_loss 0.03905671834945679 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2510 -> prob_abs_loss 0.03903681039810181 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2520 -> prob_abs_loss 0.03903001546859741 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2530 -> prob_abs_loss 0.03902775049209595 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2540 -> prob_abs_loss 0.038973987102508545 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2550 -> prob_abs_loss 0.0388871431350708 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2560 -> prob_abs_loss 0.03885853290557861 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 2570 -> prob_abs_loss 0.0388486385345459 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2580 -> prob_abs_loss 0.03884530067443848 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2590 -> prob_abs_loss 0.038762569427490234 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2600 -> prob_abs_loss 0.03869223594665527 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2610 -> prob_abs_loss 0.0386691689491272 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2620 -> prob_abs_loss 0.038661062717437744 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2630 -> prob_abs_loss 0.038658320903778076 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2640 -> prob_abs_loss 0.0386086106300354 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2650 -> prob_abs_loss 0.03852802515029907 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2660 -> prob_abs_loss 0.03850150108337402 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 2670 -> prob_abs_loss 0.03849238157272339 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2680 -> prob_abs_loss 0.03848928213119507 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2690 -> prob_abs_loss 0.03848809003829956 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2700 -> prob_abs_loss 0.03848773241043091 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 2710 -> prob_abs_loss 0.03833979368209839 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2720 -> prob_abs_loss 0.0381779670715332 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2730 -> prob_abs_loss 0.037848591804504395 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2740 -> prob_abs_loss 0.037586748600006104 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2750 -> prob_abs_loss 0.037474751472473145 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2760 -> prob_abs_loss 0.037367045879364014 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2770 -> prob_abs_loss 0.03729206323623657 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2780 -> prob_abs_loss 0.03721415996551514 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2790 -> prob_abs_loss 0.03715991973876953 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2800 -> prob_abs_loss 0.03714174032211304 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2810 -> prob_abs_loss 0.037135541439056396 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 2820 -> prob_abs_loss 0.03713327646255493 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2830 -> prob_abs_loss 0.03713256120681763 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2840 -> prob_abs_loss 0.037132322788238525 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2850 -> prob_abs_loss 0.037132203578948975 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2860 -> prob_abs_loss 0.037089645862579346 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2870 -> prob_abs_loss 0.03689169883728027 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2880 -> prob_abs_loss 0.036807894706726074 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2890 -> prob_abs_loss 0.036779582500457764 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 2900 -> prob_abs_loss 0.03672933578491211 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2910 -> prob_abs_loss 0.03666049242019653 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2920 -> prob_abs_loss 0.036637961864471436 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2930 -> prob_abs_loss 0.036630332469940186 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 2940 -> prob_abs_loss 0.036627769470214844 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 2950 -> prob_abs_loss 0.03662693500518799 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2960 -> prob_abs_loss 0.03654325008392334 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 2970 -> prob_abs_loss 0.03647160530090332 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 2980 -> prob_abs_loss 0.03644806146621704 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 2990 -> prob_abs_loss 0.036287128925323486 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 3000 -> prob_abs_loss 0.03623694181442261 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 3010 -> prob_abs_loss 0.036220014095306396 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 3020 -> prob_abs_loss 0.03621405363082886 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 3030 -> prob_abs_loss 0.036212027072906494 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3040 -> prob_abs_loss 0.03621131181716919 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3050 -> prob_abs_loss 0.03621107339859009 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3060 -> prob_abs_loss 0.03621095418930054 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3070 -> prob_abs_loss 0.03621095418930054 | sampled_mse_loss 2.0\n",
      "Epoch 3080 -> prob_abs_loss 0.03621095418930054 | sampled_mse_loss 6.0\n",
      "Epoch 3090 -> prob_abs_loss 0.036210834980010986 | sampled_mse_loss 8.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3100 -> prob_abs_loss 0.036210834980010986 | sampled_mse_loss 3.0\n",
      "Epoch 3110 -> prob_abs_loss 0.03614550828933716 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3120 -> prob_abs_loss 0.03601109981536865 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 3130 -> prob_abs_loss 0.0357816219329834 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3140 -> prob_abs_loss 0.035633087158203125 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3150 -> prob_abs_loss 0.035584092140197754 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3160 -> prob_abs_loss 0.035567402839660645 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3170 -> prob_abs_loss 0.035561442375183105 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3180 -> prob_abs_loss 0.035472095012664795 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3190 -> prob_abs_loss 0.03543102741241455 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3200 -> prob_abs_loss 0.035417020320892334 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3210 -> prob_abs_loss 0.0354122519493103 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3220 -> prob_abs_loss 0.03531992435455322 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3230 -> prob_abs_loss 0.03527039289474487 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3240 -> prob_abs_loss 0.035253822803497314 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3250 -> prob_abs_loss 0.03524810075759888 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3260 -> prob_abs_loss 0.035246193408966064 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3270 -> prob_abs_loss 0.03524535894393921 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3280 -> prob_abs_loss 0.03524512052536011 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3290 -> prob_abs_loss 0.03509312868118286 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3300 -> prob_abs_loss 0.03499293327331543 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3310 -> prob_abs_loss 0.03496021032333374 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3320 -> prob_abs_loss 0.03494906425476074 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3330 -> prob_abs_loss 0.03488588333129883 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3340 -> prob_abs_loss 0.03483313322067261 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3350 -> prob_abs_loss 0.03481549024581909 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3360 -> prob_abs_loss 0.03480952978134155 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3370 -> prob_abs_loss 0.03480738401412964 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3380 -> prob_abs_loss 0.034631192684173584 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3390 -> prob_abs_loss 0.03443431854248047 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3400 -> prob_abs_loss 0.034365832805633545 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3410 -> prob_abs_loss 0.03434270620346069 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3420 -> prob_abs_loss 0.034334778785705566 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3430 -> prob_abs_loss 0.0343320369720459 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3440 -> prob_abs_loss 0.03419351577758789 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3450 -> prob_abs_loss 0.03413289785385132 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3460 -> prob_abs_loss 0.03411293029785156 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3470 -> prob_abs_loss 0.033961355686187744 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3480 -> prob_abs_loss 0.033879876136779785 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3490 -> prob_abs_loss 0.033802330493927 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3500 -> prob_abs_loss 0.033666133880615234 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3510 -> prob_abs_loss 0.033622562885284424 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3520 -> prob_abs_loss 0.03360778093338013 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3530 -> prob_abs_loss 0.033602774143218994 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 3540 -> prob_abs_loss 0.03345412015914917 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3550 -> prob_abs_loss 0.033275485038757324 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 3560 -> prob_abs_loss 0.033218443393707275 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3570 -> prob_abs_loss 0.0331074595451355 | sampled_mse_loss 13.0\n",
      "Model saved\n",
      "Epoch 3580 -> prob_abs_loss 0.03295624256134033 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3590 -> prob_abs_loss 0.03290766477584839 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3600 -> prob_abs_loss 0.032891273498535156 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3610 -> prob_abs_loss 0.03288555145263672 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 3620 -> prob_abs_loss 0.032883644104003906 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 3630 -> prob_abs_loss 0.03277945518493652 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3640 -> prob_abs_loss 0.032652974128723145 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3650 -> prob_abs_loss 0.032612740993499756 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3660 -> prob_abs_loss 0.03259927034378052 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3670 -> prob_abs_loss 0.032594501972198486 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3680 -> prob_abs_loss 0.03255707025527954 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3690 -> prob_abs_loss 0.03249967098236084 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3700 -> prob_abs_loss 0.03245854377746582 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 3710 -> prob_abs_loss 0.03243911266326904 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3720 -> prob_abs_loss 0.0324324369430542 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3730 -> prob_abs_loss 0.032430052757263184 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3740 -> prob_abs_loss 0.03242921829223633 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3750 -> prob_abs_loss 0.032428860664367676 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3760 -> prob_abs_loss 0.032412707805633545 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3770 -> prob_abs_loss 0.03227037191390991 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3780 -> prob_abs_loss 0.032104432582855225 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3790 -> prob_abs_loss 0.0320512056350708 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3800 -> prob_abs_loss 0.03203326463699341 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3810 -> prob_abs_loss 0.03202694654464722 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3820 -> prob_abs_loss 0.0320248007774353 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3830 -> prob_abs_loss 0.03202396631240845 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 3840 -> prob_abs_loss 0.032023727893829346 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3850 -> prob_abs_loss 0.031868934631347656 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3860 -> prob_abs_loss 0.03176546096801758 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3870 -> prob_abs_loss 0.031731247901916504 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 3880 -> prob_abs_loss 0.03171956539154053 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 3890 -> prob_abs_loss 0.03164952993392944 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3900 -> prob_abs_loss 0.031538188457489014 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3910 -> prob_abs_loss 0.031473636627197266 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 3920 -> prob_abs_loss 0.031452059745788574 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3930 -> prob_abs_loss 0.031444549560546875 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3940 -> prob_abs_loss 0.031442105770111084 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3950 -> prob_abs_loss 0.03137022256851196 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3960 -> prob_abs_loss 0.03129076957702637 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 3970 -> prob_abs_loss 0.031265318393707275 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 3980 -> prob_abs_loss 0.03114616870880127 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 3990 -> prob_abs_loss 0.031083881855010986 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4000 -> prob_abs_loss 0.031063199043273926 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4010 -> prob_abs_loss 0.03105604648590088 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4020 -> prob_abs_loss 0.031053543090820312 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4030 -> prob_abs_loss 0.031052708625793457 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4040 -> prob_abs_loss 0.031052350997924805 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4050 -> prob_abs_loss 0.031052231788635254 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4060 -> prob_abs_loss 0.031052112579345703 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 4070 -> prob_abs_loss 0.030977725982666016 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4080 -> prob_abs_loss 0.03086930513381958 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4090 -> prob_abs_loss 0.030801832675933838 | sampled_mse_loss 5.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4100 -> prob_abs_loss 0.030581414699554443 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 4110 -> prob_abs_loss 0.030293524265289307 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4120 -> prob_abs_loss 0.030169427394866943 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4130 -> prob_abs_loss 0.030086517333984375 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4140 -> prob_abs_loss 0.03005880117416382 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 4150 -> prob_abs_loss 0.030049264430999756 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4160 -> prob_abs_loss 0.030045926570892334 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4170 -> prob_abs_loss 0.0299718976020813 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4180 -> prob_abs_loss 0.02976226806640625 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4190 -> prob_abs_loss 0.029688596725463867 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4200 -> prob_abs_loss 0.029663681983947754 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4210 -> prob_abs_loss 0.029655098915100098 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4220 -> prob_abs_loss 0.029652118682861328 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4230 -> prob_abs_loss 0.02965092658996582 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4240 -> prob_abs_loss 0.029650568962097168 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4250 -> prob_abs_loss 0.029650449752807617 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4260 -> prob_abs_loss 0.029608190059661865 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 4270 -> prob_abs_loss 0.0295412540435791 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4280 -> prob_abs_loss 0.029519855976104736 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4290 -> prob_abs_loss 0.02951258420944214 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4300 -> prob_abs_loss 0.029510080814361572 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4310 -> prob_abs_loss 0.029509246349334717 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4320 -> prob_abs_loss 0.029508888721466064 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4330 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4340 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 4.0\n",
      "Epoch 4350 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 6.0\n",
      "Epoch 4360 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 4.0\n",
      "Epoch 4370 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 2.0\n",
      "Epoch 4380 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 5.0\n",
      "Epoch 4390 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 2.0\n",
      "Epoch 4400 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 3.0\n",
      "Epoch 4410 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 5.0\n",
      "Epoch 4420 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 5.0\n",
      "Epoch 4430 -> prob_abs_loss 0.029508769512176514 | sampled_mse_loss 1.0\n",
      "Epoch 4440 -> prob_abs_loss 0.029407143592834473 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4450 -> prob_abs_loss 0.0293617844581604 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4460 -> prob_abs_loss 0.029322028160095215 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4470 -> prob_abs_loss 0.029169857501983643 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4480 -> prob_abs_loss 0.02890700101852417 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 4490 -> prob_abs_loss 0.028823256492614746 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4500 -> prob_abs_loss 0.028749823570251465 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4510 -> prob_abs_loss 0.028626859188079834 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4520 -> prob_abs_loss 0.0285874605178833 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 4530 -> prob_abs_loss 0.028574109077453613 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4540 -> prob_abs_loss 0.028569459915161133 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 4550 -> prob_abs_loss 0.028567910194396973 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4560 -> prob_abs_loss 0.028567194938659668 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4570 -> prob_abs_loss 0.02850741147994995 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4580 -> prob_abs_loss 0.028456807136535645 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4590 -> prob_abs_loss 0.02844017744064331 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 4600 -> prob_abs_loss 0.028434574604034424 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 4610 -> prob_abs_loss 0.02843254804611206 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4620 -> prob_abs_loss 0.028431832790374756 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4630 -> prob_abs_loss 0.028431594371795654 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4640 -> prob_abs_loss 0.02838277816772461 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4650 -> prob_abs_loss 0.02831733226776123 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4660 -> prob_abs_loss 0.028243303298950195 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4670 -> prob_abs_loss 0.028081893920898438 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4680 -> prob_abs_loss 0.02796494960784912 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4690 -> prob_abs_loss 0.0279199481010437 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 4700 -> prob_abs_loss 0.0279044508934021 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4710 -> prob_abs_loss 0.027899205684661865 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4720 -> prob_abs_loss 0.027897417545318604 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4730 -> prob_abs_loss 0.027780354022979736 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4740 -> prob_abs_loss 0.027743935585021973 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 4750 -> prob_abs_loss 0.027651727199554443 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4760 -> prob_abs_loss 0.027595162391662598 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4770 -> prob_abs_loss 0.027576684951782227 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4780 -> prob_abs_loss 0.02744525671005249 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 4790 -> prob_abs_loss 0.02734053134918213 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4800 -> prob_abs_loss 0.02726203203201294 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4810 -> prob_abs_loss 0.027218878269195557 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 4820 -> prob_abs_loss 0.027118384838104248 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 4830 -> prob_abs_loss 0.02708655595779419 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4840 -> prob_abs_loss 0.027035117149353027 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4850 -> prob_abs_loss 0.026995599269866943 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4860 -> prob_abs_loss 0.026982367038726807 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4870 -> prob_abs_loss 0.026977837085723877 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4880 -> prob_abs_loss 0.026949405670166016 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 4890 -> prob_abs_loss 0.026651442050933838 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4900 -> prob_abs_loss 0.026544392108917236 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4910 -> prob_abs_loss 0.026508808135986328 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4920 -> prob_abs_loss 0.026496589183807373 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4930 -> prob_abs_loss 0.026492297649383545 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 4940 -> prob_abs_loss 0.026454806327819824 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 4950 -> prob_abs_loss 0.02639549970626831 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4960 -> prob_abs_loss 0.02637612819671631 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4970 -> prob_abs_loss 0.026369452476501465 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 4980 -> prob_abs_loss 0.0263671875 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 4990 -> prob_abs_loss 0.026366353034973145 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5000 -> prob_abs_loss 0.026365995407104492 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 5010 -> prob_abs_loss 0.026365995407104492 | sampled_mse_loss 4.0\n",
      "Epoch 5020 -> prob_abs_loss 0.02636587619781494 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5030 -> prob_abs_loss 0.02636587619781494 | sampled_mse_loss 3.0\n",
      "Epoch 5040 -> prob_abs_loss 0.02636587619781494 | sampled_mse_loss 3.0\n",
      "Epoch 5050 -> prob_abs_loss 0.026228249073028564 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5060 -> prob_abs_loss 0.02616828680038452 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5070 -> prob_abs_loss 0.02614837884902954 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5080 -> prob_abs_loss 0.026141583919525146 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5090 -> prob_abs_loss 0.026139259338378906 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5100 -> prob_abs_loss 0.02613842487335205 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5110 -> prob_abs_loss 0.026126980781555176 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5120 -> prob_abs_loss 0.02606719732284546 | sampled_mse_loss 1.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5130 -> prob_abs_loss 0.026048362255096436 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5140 -> prob_abs_loss 0.02590346336364746 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5150 -> prob_abs_loss 0.025744318962097168 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5160 -> prob_abs_loss 0.02563035488128662 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5170 -> prob_abs_loss 0.025494873523712158 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5180 -> prob_abs_loss 0.02545088529586792 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5190 -> prob_abs_loss 0.02543550729751587 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 5200 -> prob_abs_loss 0.025430262088775635 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5210 -> prob_abs_loss 0.025395691394805908 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5220 -> prob_abs_loss 0.025342106819152832 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5230 -> prob_abs_loss 0.02532482147216797 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5240 -> prob_abs_loss 0.025318622589111328 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5250 -> prob_abs_loss 0.02531665563583374 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5260 -> prob_abs_loss 0.025315940380096436 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5270 -> prob_abs_loss 0.025315701961517334 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5280 -> prob_abs_loss 0.025315582752227783 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 5290 -> prob_abs_loss 0.025315582752227783 | sampled_mse_loss 5.0\n",
      "Epoch 5300 -> prob_abs_loss 0.025315582752227783 | sampled_mse_loss 3.0\n",
      "Epoch 5310 -> prob_abs_loss 0.025315582752227783 | sampled_mse_loss 4.0\n",
      "Epoch 5320 -> prob_abs_loss 0.025257110595703125 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 5330 -> prob_abs_loss 0.025111913681030273 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5340 -> prob_abs_loss 0.02502495050430298 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5350 -> prob_abs_loss 0.024926185607910156 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5360 -> prob_abs_loss 0.024838745594024658 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5370 -> prob_abs_loss 0.02471369504928589 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5380 -> prob_abs_loss 0.024673819541931152 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5390 -> prob_abs_loss 0.024660170078277588 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5400 -> prob_abs_loss 0.024655401706695557 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5410 -> prob_abs_loss 0.02461642026901245 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5420 -> prob_abs_loss 0.024603426456451416 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 5430 -> prob_abs_loss 0.024599134922027588 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 5440 -> prob_abs_loss 0.024597644805908203 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5450 -> prob_abs_loss 0.02459704875946045 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5460 -> prob_abs_loss 0.0245969295501709 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5470 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5480 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 5.0\n",
      "Epoch 5490 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 3.0\n",
      "Epoch 5500 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 1.0\n",
      "Epoch 5510 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 6.0\n",
      "Epoch 5520 -> prob_abs_loss 0.024596810340881348 | sampled_mse_loss 3.0\n",
      "Epoch 5530 -> prob_abs_loss 0.02454453706741333 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 5540 -> prob_abs_loss 0.024499058723449707 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5550 -> prob_abs_loss 0.024483919143676758 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5560 -> prob_abs_loss 0.024478673934936523 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5570 -> prob_abs_loss 0.02447688579559326 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5580 -> prob_abs_loss 0.024476289749145508 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5590 -> prob_abs_loss 0.024476051330566406 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5600 -> prob_abs_loss 0.02444976568222046 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 5610 -> prob_abs_loss 0.02438223361968994 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5620 -> prob_abs_loss 0.024360179901123047 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5630 -> prob_abs_loss 0.024339377880096436 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5640 -> prob_abs_loss 0.02430206537246704 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5650 -> prob_abs_loss 0.02428990602493286 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5660 -> prob_abs_loss 0.024262666702270508 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5670 -> prob_abs_loss 0.024211764335632324 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5680 -> prob_abs_loss 0.02416759729385376 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5690 -> prob_abs_loss 0.024153411388397217 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5700 -> prob_abs_loss 0.024148762226104736 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 5710 -> prob_abs_loss 0.024147093296051025 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 5720 -> prob_abs_loss 0.02414649724960327 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 5730 -> prob_abs_loss 0.024102389812469482 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5740 -> prob_abs_loss 0.024065136909484863 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5750 -> prob_abs_loss 0.024052977561950684 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5760 -> prob_abs_loss 0.024048805236816406 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 5770 -> prob_abs_loss 0.024047255516052246 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5780 -> prob_abs_loss 0.024046778678894043 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 5790 -> prob_abs_loss 0.024015426635742188 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5800 -> prob_abs_loss 0.023965418338775635 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5810 -> prob_abs_loss 0.02394932508468628 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5820 -> prob_abs_loss 0.023943960666656494 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5830 -> prob_abs_loss 0.02394205331802368 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5840 -> prob_abs_loss 0.023941338062286377 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5850 -> prob_abs_loss 0.023941099643707275 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 5860 -> prob_abs_loss 0.02386462688446045 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5870 -> prob_abs_loss 0.023800432682037354 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5880 -> prob_abs_loss 0.023779749870300293 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 5890 -> prob_abs_loss 0.023772597312927246 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5900 -> prob_abs_loss 0.023679494857788086 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5910 -> prob_abs_loss 0.023622334003448486 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5920 -> prob_abs_loss 0.023515820503234863 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 5930 -> prob_abs_loss 0.023480713367462158 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5940 -> prob_abs_loss 0.023377597332000732 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 5950 -> prob_abs_loss 0.023324787616729736 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5960 -> prob_abs_loss 0.023307502269744873 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 5970 -> prob_abs_loss 0.023257315158843994 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 5980 -> prob_abs_loss 0.023206233978271484 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 5990 -> prob_abs_loss 0.023189663887023926 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6000 -> prob_abs_loss 0.02318406105041504 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6010 -> prob_abs_loss 0.023182153701782227 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6020 -> prob_abs_loss 0.023181438446044922 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6030 -> prob_abs_loss 0.02318120002746582 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6040 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6050 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 3.0\n",
      "Epoch 6060 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 3.0\n",
      "Epoch 6070 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 4.0\n",
      "Epoch 6080 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 1.0\n",
      "Epoch 6090 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 4.0\n",
      "Epoch 6100 -> prob_abs_loss 0.02318108081817627 | sampled_mse_loss 1.0\n",
      "Epoch 6110 -> prob_abs_loss 0.023153245449066162 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6120 -> prob_abs_loss 0.02310878038406372 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6130 -> prob_abs_loss 0.023094594478607178 | sampled_mse_loss 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Epoch 6140 -> prob_abs_loss 0.02302306890487671 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6150 -> prob_abs_loss 0.02294546365737915 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6160 -> prob_abs_loss 0.022840023040771484 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6170 -> prob_abs_loss 0.02273041009902954 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6180 -> prob_abs_loss 0.02268749475479126 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6190 -> prob_abs_loss 0.022624850273132324 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6200 -> prob_abs_loss 0.022544562816619873 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6210 -> prob_abs_loss 0.02251899242401123 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6220 -> prob_abs_loss 0.022510409355163574 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6230 -> prob_abs_loss 0.022507429122924805 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6240 -> prob_abs_loss 0.022506356239318848 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6250 -> prob_abs_loss 0.022505998611450195 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6260 -> prob_abs_loss 0.022505879402160645 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6270 -> prob_abs_loss 0.022505760192871094 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6280 -> prob_abs_loss 0.022505760192871094 | sampled_mse_loss 3.0\n",
      "Epoch 6290 -> prob_abs_loss 0.02240729331970215 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6300 -> prob_abs_loss 0.0223771333694458 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6310 -> prob_abs_loss 0.022367119789123535 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6320 -> prob_abs_loss 0.02229785919189453 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6330 -> prob_abs_loss 0.022276103496551514 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6340 -> prob_abs_loss 0.022268593311309814 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6350 -> prob_abs_loss 0.022266089916229248 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6360 -> prob_abs_loss 0.02226501703262329 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6370 -> prob_abs_loss 0.02226477861404419 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6380 -> prob_abs_loss 0.02226465940475464 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6390 -> prob_abs_loss 0.02226465940475464 | sampled_mse_loss 5.0\n",
      "Epoch 6400 -> prob_abs_loss 0.02226465940475464 | sampled_mse_loss 1.0\n",
      "Epoch 6410 -> prob_abs_loss 0.022241652011871338 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6420 -> prob_abs_loss 0.022183895111083984 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6430 -> prob_abs_loss 0.022165536880493164 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6440 -> prob_abs_loss 0.02209615707397461 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6450 -> prob_abs_loss 0.022049367427825928 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6460 -> prob_abs_loss 0.02203381061553955 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6470 -> prob_abs_loss 0.021952688694000244 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6480 -> prob_abs_loss 0.021884560585021973 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6490 -> prob_abs_loss 0.021862030029296875 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6500 -> prob_abs_loss 0.021854281425476074 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6510 -> prob_abs_loss 0.021851539611816406 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6520 -> prob_abs_loss 0.02178722620010376 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 6530 -> prob_abs_loss 0.021762490272521973 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6540 -> prob_abs_loss 0.02175426483154297 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6550 -> prob_abs_loss 0.0217512845993042 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6560 -> prob_abs_loss 0.02172398567199707 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6570 -> prob_abs_loss 0.021646201610565186 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6580 -> prob_abs_loss 0.02161794900894165 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6590 -> prob_abs_loss 0.0215909481048584 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6600 -> prob_abs_loss 0.02154254913330078 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6610 -> prob_abs_loss 0.021526813507080078 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6620 -> prob_abs_loss 0.021521687507629395 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 6630 -> prob_abs_loss 0.021519780158996582 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6640 -> prob_abs_loss 0.021519064903259277 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6650 -> prob_abs_loss 0.021471917629241943 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6660 -> prob_abs_loss 0.021396636962890625 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6670 -> prob_abs_loss 0.021372497081756592 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6680 -> prob_abs_loss 0.021364152431488037 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6690 -> prob_abs_loss 0.02136129140853882 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6700 -> prob_abs_loss 0.021360337734222412 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 6710 -> prob_abs_loss 0.02135998010635376 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6720 -> prob_abs_loss 0.02135986089706421 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6730 -> prob_abs_loss 0.02135986089706421 | sampled_mse_loss 0.0\n",
      "Epoch 6740 -> prob_abs_loss 0.02135986089706421 | sampled_mse_loss 3.0\n",
      "Epoch 6750 -> prob_abs_loss 0.021359741687774658 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 6760 -> prob_abs_loss 0.021359741687774658 | sampled_mse_loss 3.0\n",
      "Epoch 6770 -> prob_abs_loss 0.021323084831237793 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6780 -> prob_abs_loss 0.021298527717590332 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6790 -> prob_abs_loss 0.02129054069519043 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6800 -> prob_abs_loss 0.02128767967224121 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6810 -> prob_abs_loss 0.021286725997924805 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6820 -> prob_abs_loss 0.021286487579345703 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6830 -> prob_abs_loss 0.021286368370056152 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6840 -> prob_abs_loss 0.0212862491607666 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6850 -> prob_abs_loss 0.02118384838104248 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6860 -> prob_abs_loss 0.021070659160614014 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6870 -> prob_abs_loss 0.02102077007293701 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6880 -> prob_abs_loss 0.020973265171051025 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6890 -> prob_abs_loss 0.020957529544830322 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6900 -> prob_abs_loss 0.02092278003692627 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6910 -> prob_abs_loss 0.020782530307769775 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 6920 -> prob_abs_loss 0.02070295810699463 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6930 -> prob_abs_loss 0.020676374435424805 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 6940 -> prob_abs_loss 0.020667314529418945 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 6950 -> prob_abs_loss 0.020664215087890625 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 6960 -> prob_abs_loss 0.020663022994995117 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 6970 -> prob_abs_loss 0.020662665367126465 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 6980 -> prob_abs_loss 0.020589709281921387 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 6990 -> prob_abs_loss 0.020547866821289062 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7000 -> prob_abs_loss 0.02053391933441162 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7010 -> prob_abs_loss 0.02052915096282959 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7020 -> prob_abs_loss 0.02052748203277588 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7030 -> prob_abs_loss 0.02050483226776123 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7040 -> prob_abs_loss 0.02049243450164795 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7050 -> prob_abs_loss 0.02048814296722412 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7060 -> prob_abs_loss 0.020442664623260498 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7070 -> prob_abs_loss 0.020413219928741455 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 7080 -> prob_abs_loss 0.02040344476699829 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 7090 -> prob_abs_loss 0.02040022611618042 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7100 -> prob_abs_loss 0.020399153232574463 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7110 -> prob_abs_loss 0.02039879560470581 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7120 -> prob_abs_loss 0.02039867639541626 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7130 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7140 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7150 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 5.0\n",
      "Epoch 7160 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 8.0\n",
      "Epoch 7170 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 6.0\n",
      "Epoch 7180 -> prob_abs_loss 0.02039855718612671 | sampled_mse_loss 2.0\n",
      "Epoch 7190 -> prob_abs_loss 0.020224690437316895 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7200 -> prob_abs_loss 0.020099163055419922 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7210 -> prob_abs_loss 0.020058929920196533 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 7220 -> prob_abs_loss 0.020045220851898193 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7230 -> prob_abs_loss 0.020040512084960938 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7240 -> prob_abs_loss 0.020038843154907227 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7250 -> prob_abs_loss 0.020038247108459473 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7260 -> prob_abs_loss 0.020007550716400146 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7270 -> prob_abs_loss 0.019981205463409424 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7280 -> prob_abs_loss 0.019972622394561768 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7290 -> prob_abs_loss 0.019969522953033447 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7300 -> prob_abs_loss 0.01996856927871704 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 7310 -> prob_abs_loss 0.01996821165084839 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7320 -> prob_abs_loss 0.019968092441558838 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 7330 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 7340 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 2.0\n",
      "Epoch 7350 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 4.0\n",
      "Epoch 7360 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 5.0\n",
      "Epoch 7370 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 4.0\n",
      "Epoch 7380 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 1.0\n",
      "Epoch 7390 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 3.0\n",
      "Epoch 7400 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 6.0\n",
      "Epoch 7410 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 3.0\n",
      "Epoch 7420 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 4.0\n",
      "Epoch 7430 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 5.0\n",
      "Epoch 7440 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 3.0\n",
      "Epoch 7450 -> prob_abs_loss 0.019967973232269287 | sampled_mse_loss 12.0\n",
      "Epoch 7460 -> prob_abs_loss 0.019945383071899414 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7470 -> prob_abs_loss 0.019888758659362793 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7480 -> prob_abs_loss 0.019870996475219727 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7490 -> prob_abs_loss 0.019865095615386963 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7500 -> prob_abs_loss 0.01986294984817505 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 7510 -> prob_abs_loss 0.019862234592437744 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7520 -> prob_abs_loss 0.019861996173858643 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 7530 -> prob_abs_loss 0.019861876964569092 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7540 -> prob_abs_loss 0.019861876964569092 | sampled_mse_loss 0.0\n",
      "Epoch 7550 -> prob_abs_loss 0.019850432872772217 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7560 -> prob_abs_loss 0.019821345806121826 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7570 -> prob_abs_loss 0.019811928272247314 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 7580 -> prob_abs_loss 0.019808828830718994 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7590 -> prob_abs_loss 0.019807755947113037 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7600 -> prob_abs_loss 0.019807279109954834 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7610 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 7620 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 6.0\n",
      "Epoch 7630 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 7.0\n",
      "Epoch 7640 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 4.0\n",
      "Epoch 7650 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 2.0\n",
      "Epoch 7660 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 3.0\n",
      "Epoch 7670 -> prob_abs_loss 0.019807159900665283 | sampled_mse_loss 6.0\n",
      "Epoch 7680 -> prob_abs_loss 0.019791781902313232 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7690 -> prob_abs_loss 0.019766569137573242 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7700 -> prob_abs_loss 0.019758224487304688 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 7710 -> prob_abs_loss 0.01975536346435547 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7720 -> prob_abs_loss 0.01975429058074951 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7730 -> prob_abs_loss 0.01975393295288086 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7740 -> prob_abs_loss 0.01975381374359131 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 7750 -> prob_abs_loss 0.01975381374359131 | sampled_mse_loss 2.0\n",
      "Epoch 7760 -> prob_abs_loss 0.01975381374359131 | sampled_mse_loss 4.0\n",
      "Epoch 7770 -> prob_abs_loss 0.01975381374359131 | sampled_mse_loss 1.0\n",
      "Epoch 7780 -> prob_abs_loss 0.019740700721740723 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7790 -> prob_abs_loss 0.019670307636260986 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7800 -> prob_abs_loss 0.019648194313049316 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7810 -> prob_abs_loss 0.019640803337097168 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7820 -> prob_abs_loss 0.01963818073272705 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7830 -> prob_abs_loss 0.019637346267700195 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7840 -> prob_abs_loss 0.019636988639831543 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7850 -> prob_abs_loss 0.019636869430541992 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7860 -> prob_abs_loss 0.019636869430541992 | sampled_mse_loss 5.0\n",
      "Epoch 7870 -> prob_abs_loss 0.019636869430541992 | sampled_mse_loss 5.0\n",
      "Epoch 7880 -> prob_abs_loss 0.01963675022125244 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7890 -> prob_abs_loss 0.01959967613220215 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 7900 -> prob_abs_loss 0.01956796646118164 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7910 -> prob_abs_loss 0.019557654857635498 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 7920 -> prob_abs_loss 0.019358813762664795 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 7930 -> prob_abs_loss 0.01915031671524048 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 7940 -> prob_abs_loss 0.019083917140960693 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 7950 -> prob_abs_loss 0.019061386585235596 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 7960 -> prob_abs_loss 0.019008398056030273 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 7970 -> prob_abs_loss 0.018991589546203613 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 7980 -> prob_abs_loss 0.018940865993499756 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 7990 -> prob_abs_loss 0.018901526927947998 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8000 -> prob_abs_loss 0.018888533115386963 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8010 -> prob_abs_loss 0.018848776817321777 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8020 -> prob_abs_loss 0.018791377544403076 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8030 -> prob_abs_loss 0.018773138523101807 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8040 -> prob_abs_loss 0.018767058849334717 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8050 -> prob_abs_loss 0.018764913082122803 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8060 -> prob_abs_loss 0.018764078617095947 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 8070 -> prob_abs_loss 0.01867210865020752 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8080 -> prob_abs_loss 0.018632471561431885 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8090 -> prob_abs_loss 0.018619239330291748 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8100 -> prob_abs_loss 0.0185624361038208 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8110 -> prob_abs_loss 0.018462061882019043 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8120 -> prob_abs_loss 0.018364250659942627 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8130 -> prob_abs_loss 0.018283367156982422 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8140 -> prob_abs_loss 0.018256723880767822 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 8150 -> prob_abs_loss 0.018247544765472412 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8160 -> prob_abs_loss 0.01817953586578369 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8170 -> prob_abs_loss 0.01814413070678711 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8180 -> prob_abs_loss 0.018132567405700684 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8190 -> prob_abs_loss 0.01812875270843506 | sampled_mse_loss 6.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8200 -> prob_abs_loss 0.01812732219696045 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8210 -> prob_abs_loss 0.018126845359802246 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8220 -> prob_abs_loss 0.018126726150512695 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8230 -> prob_abs_loss 0.01808035373687744 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8240 -> prob_abs_loss 0.018065929412841797 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8250 -> prob_abs_loss 0.018061041831970215 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 8260 -> prob_abs_loss 0.018059372901916504 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8270 -> prob_abs_loss 0.01802128553390503 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8280 -> prob_abs_loss 0.017988979816436768 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8290 -> prob_abs_loss 0.017978131771087646 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8300 -> prob_abs_loss 0.017931878566741943 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8310 -> prob_abs_loss 0.017857730388641357 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8320 -> prob_abs_loss 0.01778852939605713 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8330 -> prob_abs_loss 0.017766237258911133 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8340 -> prob_abs_loss 0.017758727073669434 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8350 -> prob_abs_loss 0.017756104469299316 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8360 -> prob_abs_loss 0.01775503158569336 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8370 -> prob_abs_loss 0.017754793167114258 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8380 -> prob_abs_loss 0.017754673957824707 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 8390 -> prob_abs_loss 0.017754554748535156 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8400 -> prob_abs_loss 0.017754554748535156 | sampled_mse_loss 5.0\n",
      "Epoch 8410 -> prob_abs_loss 0.017754554748535156 | sampled_mse_loss 5.0\n",
      "Epoch 8420 -> prob_abs_loss 0.017754554748535156 | sampled_mse_loss 5.0\n",
      "Epoch 8430 -> prob_abs_loss 0.017754554748535156 | sampled_mse_loss 1.0\n",
      "Epoch 8440 -> prob_abs_loss 0.017736077308654785 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8450 -> prob_abs_loss 0.017706871032714844 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8460 -> prob_abs_loss 0.017697453498840332 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8470 -> prob_abs_loss 0.01769423484802246 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8480 -> prob_abs_loss 0.017684102058410645 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8490 -> prob_abs_loss 0.01766103506088257 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8500 -> prob_abs_loss 0.01765352487564087 | sampled_mse_loss 13.0\n",
      "Model saved\n",
      "Epoch 8510 -> prob_abs_loss 0.017650902271270752 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8520 -> prob_abs_loss 0.017650067806243896 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8530 -> prob_abs_loss 0.01762211322784424 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8540 -> prob_abs_loss 0.01755303144454956 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8550 -> prob_abs_loss 0.017531216144561768 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8560 -> prob_abs_loss 0.01752394437789917 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8570 -> prob_abs_loss 0.017521440982818604 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8580 -> prob_abs_loss 0.017478883266448975 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8590 -> prob_abs_loss 0.017413735389709473 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8600 -> prob_abs_loss 0.017393171787261963 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8610 -> prob_abs_loss 0.017386257648468018 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8620 -> prob_abs_loss 0.017383873462677002 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8630 -> prob_abs_loss 0.017383038997650146 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8640 -> prob_abs_loss 0.017382681369781494 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 8650 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8660 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 7.0\n",
      "Epoch 8670 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 4.0\n",
      "Epoch 8680 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 3.0\n",
      "Epoch 8690 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 4.0\n",
      "Epoch 8700 -> prob_abs_loss 0.017382562160491943 | sampled_mse_loss 3.0\n",
      "Epoch 8710 -> prob_abs_loss 0.0173606276512146 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8720 -> prob_abs_loss 0.01733541488647461 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 8730 -> prob_abs_loss 0.017326951026916504 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8740 -> prob_abs_loss 0.017324090003967285 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8750 -> prob_abs_loss 0.01732313632965088 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8760 -> prob_abs_loss 0.01720219850540161 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8770 -> prob_abs_loss 0.017158567905426025 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8780 -> prob_abs_loss 0.017144083976745605 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 8790 -> prob_abs_loss 0.017139077186584473 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8800 -> prob_abs_loss 0.01713740825653076 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8810 -> prob_abs_loss 0.017136812210083008 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8820 -> prob_abs_loss 0.017136573791503906 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8830 -> prob_abs_loss 0.01703435182571411 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 8840 -> prob_abs_loss 0.016999363899230957 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8850 -> prob_abs_loss 0.016988039016723633 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8860 -> prob_abs_loss 0.016984224319458008 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 8870 -> prob_abs_loss 0.01698291301727295 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8880 -> prob_abs_loss 0.016982436180114746 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 8890 -> prob_abs_loss 0.016982316970825195 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8900 -> prob_abs_loss 0.016982197761535645 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 8910 -> prob_abs_loss 0.016982197761535645 | sampled_mse_loss 0.0\n",
      "Epoch 8920 -> prob_abs_loss 0.016982197761535645 | sampled_mse_loss 3.0\n",
      "Epoch 8930 -> prob_abs_loss 0.016959428787231445 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8940 -> prob_abs_loss 0.016902029514312744 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 8950 -> prob_abs_loss 0.016884028911590576 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8960 -> prob_abs_loss 0.016877830028533936 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8970 -> prob_abs_loss 0.0168226957321167 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 8980 -> prob_abs_loss 0.016793370246887207 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 8990 -> prob_abs_loss 0.016783714294433594 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 9000 -> prob_abs_loss 0.016780376434326172 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9010 -> prob_abs_loss 0.016779303550720215 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9020 -> prob_abs_loss 0.016778945922851562 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9030 -> prob_abs_loss 0.01677870750427246 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9040 -> prob_abs_loss 0.016738831996917725 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9050 -> prob_abs_loss 0.016723811626434326 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9060 -> prob_abs_loss 0.016718804836273193 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9070 -> prob_abs_loss 0.01671701669692993 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9080 -> prob_abs_loss 0.016716420650482178 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 9090 -> prob_abs_loss 0.016716182231903076 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9100 -> prob_abs_loss 0.016716182231903076 | sampled_mse_loss 5.0\n",
      "Epoch 9110 -> prob_abs_loss 0.016716182231903076 | sampled_mse_loss 13.0\n",
      "Epoch 9120 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9130 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 6.0\n",
      "Epoch 9140 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 5.0\n",
      "Epoch 9150 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 4.0\n",
      "Epoch 9160 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 7.0\n",
      "Epoch 9170 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 4.0\n",
      "Epoch 9180 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 2.0\n",
      "Epoch 9190 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 3.0\n",
      "Epoch 9200 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 4.0\n",
      "Epoch 9210 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 2.0\n",
      "Epoch 9220 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 8.0\n",
      "Epoch 9230 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9240 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 1.0\n",
      "Epoch 9250 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 5.0\n",
      "Epoch 9260 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 2.0\n",
      "Epoch 9270 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 5.0\n",
      "Epoch 9280 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 3.0\n",
      "Epoch 9290 -> prob_abs_loss 0.016716063022613525 | sampled_mse_loss 4.0\n",
      "Epoch 9300 -> prob_abs_loss 0.016709744930267334 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9310 -> prob_abs_loss 0.01667565107345581 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 9320 -> prob_abs_loss 0.01666468381881714 | sampled_mse_loss 12.0\n",
      "Model saved\n",
      "Epoch 9330 -> prob_abs_loss 0.016660988330841064 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9340 -> prob_abs_loss 0.016659677028656006 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9350 -> prob_abs_loss 0.016659319400787354 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9360 -> prob_abs_loss 0.016659080982208252 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9370 -> prob_abs_loss 0.016659080982208252 | sampled_mse_loss 2.0\n",
      "Epoch 9380 -> prob_abs_loss 0.016630113124847412 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9390 -> prob_abs_loss 0.01658487319946289 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9400 -> prob_abs_loss 0.016570568084716797 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9410 -> prob_abs_loss 0.016565680503845215 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 9420 -> prob_abs_loss 0.01653921604156494 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9430 -> prob_abs_loss 0.016442060470581055 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9440 -> prob_abs_loss 0.016304850578308105 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9450 -> prob_abs_loss 0.016213715076446533 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9460 -> prob_abs_loss 0.016184329986572266 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 9470 -> prob_abs_loss 0.01617431640625 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9480 -> prob_abs_loss 0.016170859336853027 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9490 -> prob_abs_loss 0.016169428825378418 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9500 -> prob_abs_loss 0.016169071197509766 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9510 -> prob_abs_loss 0.016168951988220215 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9520 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9530 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 11.0\n",
      "Epoch 9540 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 5.0\n",
      "Epoch 9550 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 5.0\n",
      "Epoch 9560 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 3.0\n",
      "Epoch 9570 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 3.0\n",
      "Epoch 9580 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 4.0\n",
      "Epoch 9590 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 4.0\n",
      "Epoch 9600 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 4.0\n",
      "Epoch 9610 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 4.0\n",
      "Epoch 9620 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 6.0\n",
      "Epoch 9630 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 2.0\n",
      "Epoch 9640 -> prob_abs_loss 0.016168832778930664 | sampled_mse_loss 6.0\n",
      "Epoch 9650 -> prob_abs_loss 0.01613295078277588 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9660 -> prob_abs_loss 0.016114115715026855 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9670 -> prob_abs_loss 0.016107916831970215 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9680 -> prob_abs_loss 0.0161057710647583 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9690 -> prob_abs_loss 0.016105055809020996 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9700 -> prob_abs_loss 0.016104817390441895 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9710 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 9720 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 4.0\n",
      "Epoch 9730 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 2.0\n",
      "Epoch 9740 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 8.0\n",
      "Epoch 9750 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 4.0\n",
      "Epoch 9760 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 7.0\n",
      "Epoch 9770 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 1.0\n",
      "Epoch 9780 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 3.0\n",
      "Epoch 9790 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 3.0\n",
      "Epoch 9800 -> prob_abs_loss 0.016104698181152344 | sampled_mse_loss 2.0\n",
      "Epoch 9810 -> prob_abs_loss 0.01608741283416748 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9820 -> prob_abs_loss 0.01604384183883667 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9830 -> prob_abs_loss 0.01603001356124878 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 9840 -> prob_abs_loss 0.016025245189666748 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 9850 -> prob_abs_loss 0.016023576259613037 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9860 -> prob_abs_loss 0.0159948468208313 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9870 -> prob_abs_loss 0.015970885753631592 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9880 -> prob_abs_loss 0.01596313714981079 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 9890 -> prob_abs_loss 0.015960514545440674 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 9900 -> prob_abs_loss 0.015959560871124268 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 9910 -> prob_abs_loss 0.015959322452545166 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 9920 -> prob_abs_loss 0.015959203243255615 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 9930 -> prob_abs_loss 0.015959203243255615 | sampled_mse_loss 6.0\n",
      "Epoch 9940 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 9950 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 2.0\n",
      "Epoch 9960 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 6.0\n",
      "Epoch 9970 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 7.0\n",
      "Epoch 9980 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 5.0\n",
      "Epoch 9990 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 1.0\n",
      "Epoch 10000 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 6.0\n",
      "Epoch 10010 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 5.0\n",
      "Epoch 10020 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 8.0\n",
      "Epoch 10030 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 3.0\n",
      "Epoch 10040 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 4.0\n",
      "Epoch 10050 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 4.0\n",
      "Epoch 10060 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 10.0\n",
      "Epoch 10070 -> prob_abs_loss 0.015959084033966064 | sampled_mse_loss 7.0\n",
      "Epoch 10080 -> prob_abs_loss 0.015926003456115723 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10090 -> prob_abs_loss 0.015874028205871582 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10100 -> prob_abs_loss 0.015857577323913574 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10110 -> prob_abs_loss 0.015851974487304688 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10120 -> prob_abs_loss 0.015850067138671875 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10130 -> prob_abs_loss 0.01584947109222412 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10140 -> prob_abs_loss 0.015833377838134766 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 10150 -> prob_abs_loss 0.015793561935424805 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10160 -> prob_abs_loss 0.015781044960021973 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10170 -> prob_abs_loss 0.015776872634887695 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10180 -> prob_abs_loss 0.015775442123413086 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10190 -> prob_abs_loss 0.015774965286254883 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10200 -> prob_abs_loss 0.01577472686767578 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10210 -> prob_abs_loss 0.0157431960105896 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10220 -> prob_abs_loss 0.01570814847946167 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10230 -> prob_abs_loss 0.015696942806243896 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10240 -> prob_abs_loss 0.015693247318267822 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10250 -> prob_abs_loss 0.015691936016082764 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10260 -> prob_abs_loss 0.015668928623199463 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10270 -> prob_abs_loss 0.015656471252441406 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10280 -> prob_abs_loss 0.01565229892730713 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10290 -> prob_abs_loss 0.01565098762512207 | sampled_mse_loss 2.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10300 -> prob_abs_loss 0.015589416027069092 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10310 -> prob_abs_loss 0.015567243099212646 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10320 -> prob_abs_loss 0.015559852123260498 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10330 -> prob_abs_loss 0.01555722951889038 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10340 -> prob_abs_loss 0.015556395053863525 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10350 -> prob_abs_loss 0.015556156635284424 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 10360 -> prob_abs_loss 0.015556037425994873 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10370 -> prob_abs_loss 0.015555918216705322 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10380 -> prob_abs_loss 0.015555918216705322 | sampled_mse_loss 4.0\n",
      "Epoch 10390 -> prob_abs_loss 0.015555918216705322 | sampled_mse_loss 10.0\n",
      "Epoch 10400 -> prob_abs_loss 0.015506148338317871 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10410 -> prob_abs_loss 0.015450835227966309 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 10420 -> prob_abs_loss 0.015433132648468018 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10430 -> prob_abs_loss 0.015427172183990479 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10440 -> prob_abs_loss 0.015391349792480469 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10450 -> prob_abs_loss 0.01533806324005127 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10460 -> prob_abs_loss 0.015321135520935059 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 10470 -> prob_abs_loss 0.015315413475036621 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10480 -> prob_abs_loss 0.015313506126403809 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 10490 -> prob_abs_loss 0.015312790870666504 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10500 -> prob_abs_loss 0.015312552452087402 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10510 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10520 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 4.0\n",
      "Epoch 10530 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 3.0\n",
      "Epoch 10540 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 7.0\n",
      "Epoch 10550 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 2.0\n",
      "Epoch 10560 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 2.0\n",
      "Epoch 10570 -> prob_abs_loss 0.015312433242797852 | sampled_mse_loss 2.0\n",
      "Epoch 10580 -> prob_abs_loss 0.015257656574249268 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 10590 -> prob_abs_loss 0.015220940113067627 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10600 -> prob_abs_loss 0.015125274658203125 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10610 -> prob_abs_loss 0.015066564083099365 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10620 -> prob_abs_loss 0.015047252178192139 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10630 -> prob_abs_loss 0.015040695667266846 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10640 -> prob_abs_loss 0.01503831148147583 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10650 -> prob_abs_loss 0.0150376558303833 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10660 -> prob_abs_loss 0.0150374174118042 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10670 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10680 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 6.0\n",
      "Epoch 10690 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 2.0\n",
      "Epoch 10700 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 3.0\n",
      "Epoch 10710 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 5.0\n",
      "Epoch 10720 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 0.0\n",
      "Epoch 10730 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 4.0\n",
      "Epoch 10740 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 3.0\n",
      "Epoch 10750 -> prob_abs_loss 0.015037178993225098 | sampled_mse_loss 5.0\n",
      "Epoch 10760 -> prob_abs_loss 0.014997601509094238 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10770 -> prob_abs_loss 0.014971733093261719 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10780 -> prob_abs_loss 0.014963388442993164 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10790 -> prob_abs_loss 0.014960527420043945 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 10800 -> prob_abs_loss 0.014959454536437988 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 10810 -> prob_abs_loss 0.014959096908569336 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 10820 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10830 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 4.0\n",
      "Epoch 10840 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 3.0\n",
      "Epoch 10850 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 6.0\n",
      "Epoch 10860 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 5.0\n",
      "Epoch 10870 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 2.0\n",
      "Epoch 10880 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 5.0\n",
      "Epoch 10890 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 8.0\n",
      "Epoch 10900 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 3.0\n",
      "Epoch 10910 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 6.0\n",
      "Epoch 10920 -> prob_abs_loss 0.014958977699279785 | sampled_mse_loss 2.0\n",
      "Epoch 10930 -> prob_abs_loss 0.014956235885620117 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 10940 -> prob_abs_loss 0.014897704124450684 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 10950 -> prob_abs_loss 0.014879107475280762 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 10960 -> prob_abs_loss 0.014872968196868896 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 10970 -> prob_abs_loss 0.014870822429656982 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 10980 -> prob_abs_loss 0.014870107173919678 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 10990 -> prob_abs_loss 0.014869749546051025 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11000 -> prob_abs_loss 0.014779090881347656 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11010 -> prob_abs_loss 0.014746308326721191 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11020 -> prob_abs_loss 0.014735519886016846 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 11030 -> prob_abs_loss 0.01473170518875122 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11040 -> prob_abs_loss 0.014712393283843994 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11050 -> prob_abs_loss 0.014683544635772705 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11060 -> prob_abs_loss 0.014630138874053955 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11070 -> prob_abs_loss 0.014583051204681396 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 11080 -> prob_abs_loss 0.014536499977111816 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11090 -> prob_abs_loss 0.014521479606628418 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11100 -> prob_abs_loss 0.014516234397888184 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 11110 -> prob_abs_loss 0.014514446258544922 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11120 -> prob_abs_loss 0.014513850212097168 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11130 -> prob_abs_loss 0.014438211917877197 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 11140 -> prob_abs_loss 0.014398694038391113 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 11150 -> prob_abs_loss 0.014334797859191895 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11160 -> prob_abs_loss 0.014252781867980957 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 11170 -> prob_abs_loss 0.014226436614990234 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11180 -> prob_abs_loss 0.01421743631362915 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11190 -> prob_abs_loss 0.01421433687210083 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11200 -> prob_abs_loss 0.014213263988494873 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11210 -> prob_abs_loss 0.01421278715133667 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11220 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11230 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 4.0\n",
      "Epoch 11240 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 6.0\n",
      "Epoch 11250 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 5.0\n",
      "Epoch 11260 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 3.0\n",
      "Epoch 11270 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 4.0\n",
      "Epoch 11280 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 2.0\n",
      "Epoch 11290 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 4.0\n",
      "Epoch 11300 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 3.0\n",
      "Epoch 11310 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 4.0\n",
      "Epoch 11320 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 6.0\n",
      "Epoch 11330 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 7.0\n",
      "Epoch 11340 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 2.0\n",
      "Epoch 11350 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 3.0\n",
      "Epoch 11360 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 5.0\n",
      "Epoch 11370 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11380 -> prob_abs_loss 0.01421266794204712 | sampled_mse_loss 6.0\n",
      "Epoch 11390 -> prob_abs_loss 0.014167964458465576 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11400 -> prob_abs_loss 0.014129877090454102 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11410 -> prob_abs_loss 0.01411736011505127 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11420 -> prob_abs_loss 0.013979494571685791 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11430 -> prob_abs_loss 0.01393735408782959 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11440 -> prob_abs_loss 0.013923287391662598 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11450 -> prob_abs_loss 0.013918399810791016 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 11460 -> prob_abs_loss 0.013916730880737305 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11470 -> prob_abs_loss 0.01391613483428955 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11480 -> prob_abs_loss 0.013916015625 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 11490 -> prob_abs_loss 0.01391589641571045 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11500 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11510 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11520 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11530 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 5.0\n",
      "Epoch 11540 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 3.0\n",
      "Epoch 11550 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 5.0\n",
      "Epoch 11560 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 2.0\n",
      "Epoch 11570 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 2.0\n",
      "Epoch 11580 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 7.0\n",
      "Epoch 11590 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 2.0\n",
      "Epoch 11600 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11610 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 3.0\n",
      "Epoch 11620 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 6.0\n",
      "Epoch 11630 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 6.0\n",
      "Epoch 11640 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 7.0\n",
      "Epoch 11650 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 6.0\n",
      "Epoch 11660 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11670 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 10.0\n",
      "Epoch 11680 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11690 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 7.0\n",
      "Epoch 11700 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11710 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 1.0\n",
      "Epoch 11720 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11730 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11740 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 3.0\n",
      "Epoch 11750 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 7.0\n",
      "Epoch 11760 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11770 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 5.0\n",
      "Epoch 11780 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 4.0\n",
      "Epoch 11790 -> prob_abs_loss 0.013915777206420898 | sampled_mse_loss 7.0\n",
      "Epoch 11800 -> prob_abs_loss 0.013884663581848145 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 11810 -> prob_abs_loss 0.013868272304534912 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 11820 -> prob_abs_loss 0.013862907886505127 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11830 -> prob_abs_loss 0.013861119747161865 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 11840 -> prob_abs_loss 0.01386040449142456 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11850 -> prob_abs_loss 0.013860166072845459 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11860 -> prob_abs_loss 0.01384061574935913 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11870 -> prob_abs_loss 0.013791441917419434 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11880 -> prob_abs_loss 0.013775944709777832 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11890 -> prob_abs_loss 0.013770699501037598 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11900 -> prob_abs_loss 0.013768792152404785 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11910 -> prob_abs_loss 0.013763904571533203 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11920 -> prob_abs_loss 0.013686895370483398 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11930 -> prob_abs_loss 0.013662397861480713 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 11940 -> prob_abs_loss 0.013654172420501709 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11950 -> prob_abs_loss 0.01365119218826294 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 11960 -> prob_abs_loss 0.013650238513946533 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 11970 -> prob_abs_loss 0.01364988088607788 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 11980 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 11990 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 1.0\n",
      "Epoch 12000 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 0.0\n",
      "Epoch 12010 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 1.0\n",
      "Epoch 12020 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 5.0\n",
      "Epoch 12030 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 2.0\n",
      "Epoch 12040 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 1.0\n",
      "Epoch 12050 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 5.0\n",
      "Epoch 12060 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 8.0\n",
      "Epoch 12070 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 3.0\n",
      "Epoch 12080 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 4.0\n",
      "Epoch 12090 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 4.0\n",
      "Epoch 12100 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 3.0\n",
      "Epoch 12110 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 9.0\n",
      "Epoch 12120 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 4.0\n",
      "Epoch 12130 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 2.0\n",
      "Epoch 12140 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 0.0\n",
      "Epoch 12150 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 7.0\n",
      "Epoch 12160 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 5.0\n",
      "Epoch 12170 -> prob_abs_loss 0.01364964246749878 | sampled_mse_loss 2.0\n",
      "Epoch 12180 -> prob_abs_loss 0.013627469539642334 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 12190 -> prob_abs_loss 0.013602912425994873 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 12200 -> prob_abs_loss 0.013595104217529297 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 12210 -> prob_abs_loss 0.01359248161315918 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 12220 -> prob_abs_loss 0.013591527938842773 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12230 -> prob_abs_loss 0.013591170310974121 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 12240 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 12250 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 7.0\n",
      "Epoch 12260 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 7.0\n",
      "Epoch 12270 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 5.0\n",
      "Epoch 12280 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 2.0\n",
      "Epoch 12290 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 3.0\n",
      "Epoch 12300 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 5.0\n",
      "Epoch 12310 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 10.0\n",
      "Epoch 12320 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 2.0\n",
      "Epoch 12330 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 6.0\n",
      "Epoch 12340 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 4.0\n",
      "Epoch 12350 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 5.0\n",
      "Epoch 12360 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 3.0\n",
      "Epoch 12370 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 4.0\n",
      "Epoch 12380 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 4.0\n",
      "Epoch 12390 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 3.0\n",
      "Epoch 12400 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 4.0\n",
      "Epoch 12410 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 2.0\n",
      "Epoch 12420 -> prob_abs_loss 0.01359105110168457 | sampled_mse_loss 2.0\n",
      "Epoch 12430 -> prob_abs_loss 0.01352161169052124 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12440 -> prob_abs_loss 0.013443827629089355 | sampled_mse_loss 6.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12450 -> prob_abs_loss 0.01341867446899414 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 12460 -> prob_abs_loss 0.013410210609436035 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 12470 -> prob_abs_loss 0.013407230377197266 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 12480 -> prob_abs_loss 0.013406157493591309 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12490 -> prob_abs_loss 0.013405680656433105 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 12500 -> prob_abs_loss 0.013405680656433105 | sampled_mse_loss 4.0\n",
      "Epoch 12510 -> prob_abs_loss 0.013405561447143555 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 12520 -> prob_abs_loss 0.013405561447143555 | sampled_mse_loss 2.0\n",
      "Epoch 12530 -> prob_abs_loss 0.013405561447143555 | sampled_mse_loss 2.0\n",
      "Epoch 12540 -> prob_abs_loss 0.013405561447143555 | sampled_mse_loss 3.0\n",
      "Epoch 12550 -> prob_abs_loss 0.013405561447143555 | sampled_mse_loss 7.0\n",
      "Epoch 12560 -> prob_abs_loss 0.013356506824493408 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 12570 -> prob_abs_loss 0.013330638408660889 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 12580 -> prob_abs_loss 0.013309657573699951 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 12590 -> prob_abs_loss 0.01324009895324707 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12600 -> prob_abs_loss 0.01321864128112793 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 12610 -> prob_abs_loss 0.013211369514465332 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 12620 -> prob_abs_loss 0.013208925724029541 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 12630 -> prob_abs_loss 0.013207972049713135 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 12640 -> prob_abs_loss 0.013160407543182373 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 12650 -> prob_abs_loss 0.013099968433380127 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 12660 -> prob_abs_loss 0.013080418109893799 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 12670 -> prob_abs_loss 0.013073861598968506 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12680 -> prob_abs_loss 0.013071596622467041 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12690 -> prob_abs_loss 0.013070881366729736 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 12700 -> prob_abs_loss 0.013070642948150635 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 12710 -> prob_abs_loss 0.013070523738861084 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 12720 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 12730 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 5.0\n",
      "Epoch 12740 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 6.0\n",
      "Epoch 12750 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12760 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 5.0\n",
      "Epoch 12770 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 8.0\n",
      "Epoch 12780 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12790 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 2.0\n",
      "Epoch 12800 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 5.0\n",
      "Epoch 12810 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 2.0\n",
      "Epoch 12820 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 7.0\n",
      "Epoch 12830 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12840 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 5.0\n",
      "Epoch 12850 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 10.0\n",
      "Epoch 12860 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 3.0\n",
      "Epoch 12870 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 3.0\n",
      "Epoch 12880 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12890 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 2.0\n",
      "Epoch 12900 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 3.0\n",
      "Epoch 12910 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 6.0\n",
      "Epoch 12920 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 3.0\n",
      "Epoch 12930 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 7.0\n",
      "Epoch 12940 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12950 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 5.0\n",
      "Epoch 12960 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 11.0\n",
      "Epoch 12970 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 3.0\n",
      "Epoch 12980 -> prob_abs_loss 0.013070404529571533 | sampled_mse_loss 4.0\n",
      "Epoch 12990 -> prob_abs_loss 0.013035356998443604 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 13000 -> prob_abs_loss 0.01301652193069458 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13010 -> prob_abs_loss 0.013010203838348389 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 13020 -> prob_abs_loss 0.013008058071136475 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13030 -> prob_abs_loss 0.01300734281539917 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13040 -> prob_abs_loss 0.013007104396820068 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 13050 -> prob_abs_loss 0.013006985187530518 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13060 -> prob_abs_loss 0.01292043924331665 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 13070 -> prob_abs_loss 0.012893617153167725 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13080 -> prob_abs_loss 0.012884557247161865 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13090 -> prob_abs_loss 0.012881457805633545 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13100 -> prob_abs_loss 0.012880384922027588 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 13110 -> prob_abs_loss 0.012880027294158936 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13120 -> prob_abs_loss 0.012879908084869385 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13130 -> prob_abs_loss 0.012879908084869385 | sampled_mse_loss 5.0\n",
      "Epoch 13140 -> prob_abs_loss 0.012879908084869385 | sampled_mse_loss 1.0\n",
      "Epoch 13150 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13160 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 7.0\n",
      "Epoch 13170 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 2.0\n",
      "Epoch 13180 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 3.0\n",
      "Epoch 13190 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 1.0\n",
      "Epoch 13200 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 1.0\n",
      "Epoch 13210 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 3.0\n",
      "Epoch 13220 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 6.0\n",
      "Epoch 13230 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 2.0\n",
      "Epoch 13240 -> prob_abs_loss 0.012879788875579834 | sampled_mse_loss 2.0\n",
      "Epoch 13250 -> prob_abs_loss 0.012842655181884766 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13260 -> prob_abs_loss 0.012811660766601562 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13270 -> prob_abs_loss 0.012801647186279297 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13280 -> prob_abs_loss 0.012798309326171875 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13290 -> prob_abs_loss 0.012797117233276367 | sampled_mse_loss 13.0\n",
      "Model saved\n",
      "Epoch 13300 -> prob_abs_loss 0.012796640396118164 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13310 -> prob_abs_loss 0.012750387191772461 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13320 -> prob_abs_loss 0.012733697891235352 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 13330 -> prob_abs_loss 0.012727975845336914 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13340 -> prob_abs_loss 0.012726068496704102 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13350 -> prob_abs_loss 0.012725353240966797 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 13360 -> prob_abs_loss 0.012725114822387695 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 13370 -> prob_abs_loss 0.012725114822387695 | sampled_mse_loss 6.0\n",
      "Epoch 13380 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13390 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 3.0\n",
      "Epoch 13400 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 4.0\n",
      "Epoch 13410 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 7.0\n",
      "Epoch 13420 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 7.0\n",
      "Epoch 13430 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 6.0\n",
      "Epoch 13440 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 6.0\n",
      "Epoch 13450 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 5.0\n",
      "Epoch 13460 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 3.0\n",
      "Epoch 13470 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 4.0\n",
      "Epoch 13480 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 5.0\n",
      "Epoch 13490 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 3.0\n",
      "Epoch 13500 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13510 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 2.0\n",
      "Epoch 13520 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 6.0\n",
      "Epoch 13530 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 4.0\n",
      "Epoch 13540 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 6.0\n",
      "Epoch 13550 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 0.0\n",
      "Epoch 13560 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 6.0\n",
      "Epoch 13570 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 5.0\n",
      "Epoch 13580 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 2.0\n",
      "Epoch 13590 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 5.0\n",
      "Epoch 13600 -> prob_abs_loss 0.012724995613098145 | sampled_mse_loss 8.0\n",
      "Epoch 13610 -> prob_abs_loss 0.012709736824035645 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 13620 -> prob_abs_loss 0.012692689895629883 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 13630 -> prob_abs_loss 0.012590289115905762 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 13640 -> prob_abs_loss 0.01251000165939331 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13650 -> prob_abs_loss 0.012449920177459717 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 13660 -> prob_abs_loss 0.012430250644683838 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13670 -> prob_abs_loss 0.012423574924468994 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 13680 -> prob_abs_loss 0.012421190738677979 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13690 -> prob_abs_loss 0.012420475482940674 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13700 -> prob_abs_loss 0.012420237064361572 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 13710 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 13720 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13730 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 1.0\n",
      "Epoch 13740 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13750 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 13760 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13770 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13780 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13790 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 13800 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13810 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13820 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 9.0\n",
      "Epoch 13830 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 1.0\n",
      "Epoch 13840 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13850 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 13860 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13870 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 7.0\n",
      "Epoch 13880 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13890 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13900 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 13910 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13920 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13930 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13940 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13950 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 7.0\n",
      "Epoch 13960 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 13970 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 7.0\n",
      "Epoch 13980 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 13990 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 1.0\n",
      "Epoch 14000 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 6.0\n",
      "Epoch 14010 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 14020 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 6.0\n",
      "Epoch 14030 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 14040 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 14050 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 14060 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 14070 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 14080 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 10.0\n",
      "Epoch 14090 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 14100 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 1.0\n",
      "Epoch 14110 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 5.0\n",
      "Epoch 14120 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 14130 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 14140 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 14150 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 7.0\n",
      "Epoch 14160 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 6.0\n",
      "Epoch 14170 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 14180 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 14190 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 2.0\n",
      "Epoch 14200 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 14210 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 4.0\n",
      "Epoch 14220 -> prob_abs_loss 0.01241999864578247 | sampled_mse_loss 3.0\n",
      "Epoch 14230 -> prob_abs_loss 0.012368917465209961 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 14240 -> prob_abs_loss 0.012342095375061035 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 14250 -> prob_abs_loss 0.012333273887634277 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14260 -> prob_abs_loss 0.012330293655395508 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14270 -> prob_abs_loss 0.01232922077178955 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14280 -> prob_abs_loss 0.01229161024093628 | sampled_mse_loss 12.0\n",
      "Model saved\n",
      "Epoch 14290 -> prob_abs_loss 0.012244164943695068 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14300 -> prob_abs_loss 0.01221698522567749 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 14310 -> prob_abs_loss 0.012208044528961182 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14320 -> prob_abs_loss 0.012205064296722412 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 14330 -> prob_abs_loss 0.012203872203826904 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14340 -> prob_abs_loss 0.012203633785247803 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14350 -> prob_abs_loss 0.012181997299194336 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14360 -> prob_abs_loss 0.012119054794311523 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14370 -> prob_abs_loss 0.01205533742904663 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 14380 -> prob_abs_loss 0.012035191059112549 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14390 -> prob_abs_loss 0.012028276920318604 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14400 -> prob_abs_loss 0.012025892734527588 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14410 -> prob_abs_loss 0.012025058269500732 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14420 -> prob_abs_loss 0.01202470064163208 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14430 -> prob_abs_loss 0.01202470064163208 | sampled_mse_loss 3.0\n",
      "Epoch 14440 -> prob_abs_loss 0.01202470064163208 | sampled_mse_loss 3.0\n",
      "Epoch 14450 -> prob_abs_loss 0.012011349201202393 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14460 -> prob_abs_loss 0.011990487575531006 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14470 -> prob_abs_loss 0.011983931064605713 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14480 -> prob_abs_loss 0.011981666088104248 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 14490 -> prob_abs_loss 0.011980831623077393 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14500 -> prob_abs_loss 0.011980593204498291 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 14510 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14520 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 3.0\n",
      "Epoch 14530 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 5.0\n",
      "Epoch 14540 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 5.0\n",
      "Epoch 14550 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 4.0\n",
      "Epoch 14560 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 3.0\n",
      "Epoch 14570 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 6.0\n",
      "Epoch 14580 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 6.0\n",
      "Epoch 14590 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 6.0\n",
      "Epoch 14600 -> prob_abs_loss 0.01198047399520874 | sampled_mse_loss 8.0\n",
      "Epoch 14610 -> prob_abs_loss 0.011958658695220947 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14620 -> prob_abs_loss 0.011934220790863037 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14630 -> prob_abs_loss 0.011926233768463135 | sampled_mse_loss 5.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14640 -> prob_abs_loss 0.011923611164093018 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14650 -> prob_abs_loss 0.011922657489776611 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14660 -> prob_abs_loss 0.011922299861907959 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14670 -> prob_abs_loss 0.011922180652618408 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14680 -> prob_abs_loss 0.011922180652618408 | sampled_mse_loss 5.0\n",
      "Epoch 14690 -> prob_abs_loss 0.011922180652618408 | sampled_mse_loss 4.0\n",
      "Epoch 14700 -> prob_abs_loss 0.011903464794158936 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14710 -> prob_abs_loss 0.01184624433517456 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14720 -> prob_abs_loss 0.011813580989837646 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14730 -> prob_abs_loss 0.011802911758422852 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14740 -> prob_abs_loss 0.011799216270446777 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14750 -> prob_abs_loss 0.01179802417755127 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 14760 -> prob_abs_loss 0.011797547340393066 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14770 -> prob_abs_loss 0.01176375150680542 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 14780 -> prob_abs_loss 0.011753499507904053 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14790 -> prob_abs_loss 0.01175004243850708 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14800 -> prob_abs_loss 0.011748850345611572 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 14810 -> prob_abs_loss 0.01174849271774292 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14820 -> prob_abs_loss 0.011634886264801025 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 14830 -> prob_abs_loss 0.011593818664550781 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 14840 -> prob_abs_loss 0.011580228805541992 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 14850 -> prob_abs_loss 0.011575579643249512 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 14860 -> prob_abs_loss 0.0115739107131958 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14870 -> prob_abs_loss 0.011573433876037598 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14880 -> prob_abs_loss 0.011573195457458496 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 14890 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 14900 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 1.0\n",
      "Epoch 14910 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 5.0\n",
      "Epoch 14920 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 9.0\n",
      "Epoch 14930 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 8.0\n",
      "Epoch 14940 -> prob_abs_loss 0.011573076248168945 | sampled_mse_loss 9.0\n",
      "Epoch 14950 -> prob_abs_loss 0.011535048484802246 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14960 -> prob_abs_loss 0.011510252952575684 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 14970 -> prob_abs_loss 0.01150214672088623 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 14980 -> prob_abs_loss 0.011499404907226562 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 14990 -> prob_abs_loss 0.011498451232910156 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15000 -> prob_abs_loss 0.011498093605041504 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15010 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15020 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 7.0\n",
      "Epoch 15030 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 2.0\n",
      "Epoch 15040 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 4.0\n",
      "Epoch 15050 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 6.0\n",
      "Epoch 15060 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 2.0\n",
      "Epoch 15070 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 0.0\n",
      "Epoch 15080 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 5.0\n",
      "Epoch 15090 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 5.0\n",
      "Epoch 15100 -> prob_abs_loss 0.011497974395751953 | sampled_mse_loss 1.0\n",
      "Epoch 15110 -> prob_abs_loss 0.011481165885925293 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15120 -> prob_abs_loss 0.011439323425292969 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 15130 -> prob_abs_loss 0.011426210403442383 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 15140 -> prob_abs_loss 0.011421799659729004 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15150 -> prob_abs_loss 0.011420249938964844 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 15160 -> prob_abs_loss 0.01141977310180664 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15170 -> prob_abs_loss 0.011419534683227539 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 15180 -> prob_abs_loss 0.011419534683227539 | sampled_mse_loss 3.0\n",
      "Epoch 15190 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15200 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 3.0\n",
      "Epoch 15210 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 4.0\n",
      "Epoch 15220 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 3.0\n",
      "Epoch 15230 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 6.0\n",
      "Epoch 15240 -> prob_abs_loss 0.011419415473937988 | sampled_mse_loss 6.0\n",
      "Epoch 15250 -> prob_abs_loss 0.01137608289718628 | sampled_mse_loss 12.0\n",
      "Model saved\n",
      "Epoch 15260 -> prob_abs_loss 0.011339366436004639 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15270 -> prob_abs_loss 0.01132744550704956 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15280 -> prob_abs_loss 0.011323392391204834 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 15290 -> prob_abs_loss 0.011321961879730225 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15300 -> prob_abs_loss 0.011321485042572021 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15310 -> prob_abs_loss 0.01132136583328247 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15320 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 15330 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 4.0\n",
      "Epoch 15340 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 6.0\n",
      "Epoch 15350 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 3.0\n",
      "Epoch 15360 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 4.0\n",
      "Epoch 15370 -> prob_abs_loss 0.01132124662399292 | sampled_mse_loss 3.0\n",
      "Epoch 15380 -> prob_abs_loss 0.011312425136566162 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 15390 -> prob_abs_loss 0.011265397071838379 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15400 -> prob_abs_loss 0.011250734329223633 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15410 -> prob_abs_loss 0.0112457275390625 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15420 -> prob_abs_loss 0.011211514472961426 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15430 -> prob_abs_loss 0.01119375228881836 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15440 -> prob_abs_loss 0.011187970638275146 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 15450 -> prob_abs_loss 0.011185824871063232 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15460 -> prob_abs_loss 0.011185228824615479 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15470 -> prob_abs_loss 0.01114267110824585 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 15480 -> prob_abs_loss 0.01107645034790039 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15490 -> prob_abs_loss 0.011055529117584229 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15500 -> prob_abs_loss 0.011048495769500732 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15510 -> prob_abs_loss 0.011046111583709717 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 15520 -> prob_abs_loss 0.01104515790939331 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15530 -> prob_abs_loss 0.011044919490814209 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 15540 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15550 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 1.0\n",
      "Epoch 15560 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 8.0\n",
      "Epoch 15570 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 6.0\n",
      "Epoch 15580 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 6.0\n",
      "Epoch 15590 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 3.0\n",
      "Epoch 15600 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 9.0\n",
      "Epoch 15610 -> prob_abs_loss 0.011044800281524658 | sampled_mse_loss 4.0\n",
      "Epoch 15620 -> prob_abs_loss 0.010986566543579102 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15630 -> prob_abs_loss 0.010955810546875 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15640 -> prob_abs_loss 0.010945737361907959 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 15650 -> prob_abs_loss 0.010886311531066895 | sampled_mse_loss 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Epoch 15660 -> prob_abs_loss 0.010864853858947754 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15670 -> prob_abs_loss 0.010857820510864258 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 15680 -> prob_abs_loss 0.010855317115783691 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15690 -> prob_abs_loss 0.010854482650756836 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15700 -> prob_abs_loss 0.010854125022888184 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15710 -> prob_abs_loss 0.010854125022888184 | sampled_mse_loss 2.0\n",
      "Epoch 15720 -> prob_abs_loss 0.010854005813598633 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15730 -> prob_abs_loss 0.010854005813598633 | sampled_mse_loss 3.0\n",
      "Epoch 15740 -> prob_abs_loss 0.010854005813598633 | sampled_mse_loss 3.0\n",
      "Epoch 15750 -> prob_abs_loss 0.010752439498901367 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15760 -> prob_abs_loss 0.01070857048034668 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 15770 -> prob_abs_loss 0.01069408655166626 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15780 -> prob_abs_loss 0.010689198970794678 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15790 -> prob_abs_loss 0.010687410831451416 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15800 -> prob_abs_loss 0.010686814785003662 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15810 -> prob_abs_loss 0.01068657636642456 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15820 -> prob_abs_loss 0.01068657636642456 | sampled_mse_loss 1.0\n",
      "Epoch 15830 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15840 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 4.0\n",
      "Epoch 15850 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 4.0\n",
      "Epoch 15860 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 5.0\n",
      "Epoch 15870 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 1.0\n",
      "Epoch 15880 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 5.0\n",
      "Epoch 15890 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 3.0\n",
      "Epoch 15900 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 4.0\n",
      "Epoch 15910 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 3.0\n",
      "Epoch 15920 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 5.0\n",
      "Epoch 15930 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 4.0\n",
      "Epoch 15940 -> prob_abs_loss 0.01068645715713501 | sampled_mse_loss 4.0\n",
      "Epoch 15950 -> prob_abs_loss 0.010635733604431152 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 15960 -> prob_abs_loss 0.010592997074127197 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 15970 -> prob_abs_loss 0.010579049587249756 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 15980 -> prob_abs_loss 0.010574281215667725 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 15990 -> prob_abs_loss 0.010572612285614014 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16000 -> prob_abs_loss 0.01057201623916626 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 16010 -> prob_abs_loss 0.010571897029876709 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 16020 -> prob_abs_loss 0.010571777820587158 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 16030 -> prob_abs_loss 0.010571777820587158 | sampled_mse_loss 3.0\n",
      "Epoch 16040 -> prob_abs_loss 0.010571777820587158 | sampled_mse_loss 3.0\n",
      "Epoch 16050 -> prob_abs_loss 0.010540187358856201 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16060 -> prob_abs_loss 0.010530173778533936 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16070 -> prob_abs_loss 0.010526716709136963 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16080 -> prob_abs_loss 0.010525524616241455 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 16090 -> prob_abs_loss 0.010525166988372803 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16100 -> prob_abs_loss 0.010525047779083252 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16110 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 16120 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 2.0\n",
      "Epoch 16130 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 5.0\n",
      "Epoch 16140 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 2.0\n",
      "Epoch 16150 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 1.0\n",
      "Epoch 16160 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 5.0\n",
      "Epoch 16170 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 4.0\n",
      "Epoch 16180 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 3.0\n",
      "Epoch 16190 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 4.0\n",
      "Epoch 16200 -> prob_abs_loss 0.010524928569793701 | sampled_mse_loss 3.0\n",
      "Epoch 16210 -> prob_abs_loss 0.010513365268707275 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16220 -> prob_abs_loss 0.010426878929138184 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16230 -> prob_abs_loss 0.010386765003204346 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 16240 -> prob_abs_loss 0.010373532772064209 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16250 -> prob_abs_loss 0.01036900281906128 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16260 -> prob_abs_loss 0.01036745309829712 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16270 -> prob_abs_loss 0.010366857051849365 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16280 -> prob_abs_loss 0.010366737842559814 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16290 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16300 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 2.0\n",
      "Epoch 16310 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 5.0\n",
      "Epoch 16320 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 5.0\n",
      "Epoch 16330 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 3.0\n",
      "Epoch 16340 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 3.0\n",
      "Epoch 16350 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 3.0\n",
      "Epoch 16360 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 2.0\n",
      "Epoch 16370 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 2.0\n",
      "Epoch 16380 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 2.0\n",
      "Epoch 16390 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 2.0\n",
      "Epoch 16400 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 8.0\n",
      "Epoch 16410 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 4.0\n",
      "Epoch 16420 -> prob_abs_loss 0.010366618633270264 | sampled_mse_loss 3.0\n",
      "Epoch 16430 -> prob_abs_loss 0.010316729545593262 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16440 -> prob_abs_loss 0.01029515266418457 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16450 -> prob_abs_loss 0.010288000106811523 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16460 -> prob_abs_loss 0.010280191898345947 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 16470 -> prob_abs_loss 0.010250508785247803 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16480 -> prob_abs_loss 0.010241210460662842 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 16490 -> prob_abs_loss 0.01023799180984497 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16500 -> prob_abs_loss 0.010185420513153076 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16510 -> prob_abs_loss 0.010151505470275879 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16520 -> prob_abs_loss 0.010140538215637207 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16530 -> prob_abs_loss 0.010136723518371582 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16540 -> prob_abs_loss 0.010135412216186523 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16550 -> prob_abs_loss 0.01013493537902832 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16560 -> prob_abs_loss 0.01013481616973877 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16570 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 16580 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16590 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16600 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 6.0\n",
      "Epoch 16610 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16620 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16630 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 4.0\n",
      "Epoch 16640 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16650 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16660 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 4.0\n",
      "Epoch 16670 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16680 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 10.0\n",
      "Epoch 16690 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16700 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 9.0\n",
      "Epoch 16710 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16720 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16730 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16740 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16750 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16760 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16770 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 7.0\n",
      "Epoch 16780 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16790 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 7.0\n",
      "Epoch 16800 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 4.0\n",
      "Epoch 16810 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16820 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 4.0\n",
      "Epoch 16830 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16840 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 5.0\n",
      "Epoch 16850 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16860 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 3.0\n",
      "Epoch 16870 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 2.0\n",
      "Epoch 16880 -> prob_abs_loss 0.010134696960449219 | sampled_mse_loss 6.0\n",
      "Epoch 16890 -> prob_abs_loss 0.010091543197631836 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 16900 -> prob_abs_loss 0.010057926177978516 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 16910 -> prob_abs_loss 0.010030865669250488 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 16920 -> prob_abs_loss 0.010022103786468506 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16930 -> prob_abs_loss 0.010019123554229736 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 16940 -> prob_abs_loss 0.01001805067062378 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16950 -> prob_abs_loss 0.010017693042755127 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16960 -> prob_abs_loss 0.010017573833465576 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 16970 -> prob_abs_loss 0.010017454624176025 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 16980 -> prob_abs_loss 0.010017454624176025 | sampled_mse_loss 5.0\n",
      "Epoch 16990 -> prob_abs_loss 0.00998908281326294 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17000 -> prob_abs_loss 0.009937465190887451 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17010 -> prob_abs_loss 0.009921133518218994 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17020 -> prob_abs_loss 0.009915649890899658 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 17030 -> prob_abs_loss 0.009913742542266846 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17040 -> prob_abs_loss 0.009913146495819092 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17050 -> prob_abs_loss 0.009913027286529541 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17060 -> prob_abs_loss 0.00991278886795044 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17070 -> prob_abs_loss 0.00991278886795044 | sampled_mse_loss 7.0\n",
      "Epoch 17080 -> prob_abs_loss 0.00991278886795044 | sampled_mse_loss 6.0\n",
      "Epoch 17090 -> prob_abs_loss 0.00991278886795044 | sampled_mse_loss 5.0\n",
      "Epoch 17100 -> prob_abs_loss 0.00991278886795044 | sampled_mse_loss 7.0\n",
      "Epoch 17110 -> prob_abs_loss 0.009900510311126709 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17120 -> prob_abs_loss 0.009834885597229004 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17130 -> prob_abs_loss 0.009814262390136719 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 17140 -> prob_abs_loss 0.009807348251342773 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17150 -> prob_abs_loss 0.009804964065551758 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17160 -> prob_abs_loss 0.009804129600524902 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17170 -> prob_abs_loss 0.00980377197265625 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17180 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17190 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 5.0\n",
      "Epoch 17200 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 4.0\n",
      "Epoch 17210 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 5.0\n",
      "Epoch 17220 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 3.0\n",
      "Epoch 17230 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 2.0\n",
      "Epoch 17240 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 3.0\n",
      "Epoch 17250 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 6.0\n",
      "Epoch 17260 -> prob_abs_loss 0.0098036527633667 | sampled_mse_loss 4.0\n",
      "Epoch 17270 -> prob_abs_loss 0.009795665740966797 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17280 -> prob_abs_loss 0.009753942489624023 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 17290 -> prob_abs_loss 0.009741067886352539 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17300 -> prob_abs_loss 0.009736776351928711 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17310 -> prob_abs_loss 0.00973522663116455 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17320 -> prob_abs_loss 0.009707450866699219 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 17330 -> prob_abs_loss 0.009664058685302734 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17340 -> prob_abs_loss 0.00965029001235962 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17350 -> prob_abs_loss 0.009645640850067139 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17360 -> prob_abs_loss 0.009643971920013428 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17370 -> prob_abs_loss 0.009643256664276123 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 17380 -> prob_abs_loss 0.009643137454986572 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17390 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 17400 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 2.0\n",
      "Epoch 17410 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 5.0\n",
      "Epoch 17420 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 6.0\n",
      "Epoch 17430 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 5.0\n",
      "Epoch 17440 -> prob_abs_loss 0.009643018245697021 | sampled_mse_loss 7.0\n",
      "Epoch 17450 -> prob_abs_loss 0.009626150131225586 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17460 -> prob_abs_loss 0.00958395004272461 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17470 -> prob_abs_loss 0.009570717811584473 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17480 -> prob_abs_loss 0.009566187858581543 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17490 -> prob_abs_loss 0.009564638137817383 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17500 -> prob_abs_loss 0.00956416130065918 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17510 -> prob_abs_loss 0.009563922882080078 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17520 -> prob_abs_loss 0.009519815444946289 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17530 -> prob_abs_loss 0.009496688842773438 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17540 -> prob_abs_loss 0.009489178657531738 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17550 -> prob_abs_loss 0.009486556053161621 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17560 -> prob_abs_loss 0.009450972080230713 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17570 -> prob_abs_loss 0.009440004825592041 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17580 -> prob_abs_loss 0.009436428546905518 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17590 -> prob_abs_loss 0.009435117244720459 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17600 -> prob_abs_loss 0.009434759616851807 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 17610 -> prob_abs_loss 0.009434521198272705 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17620 -> prob_abs_loss 0.00942140817642212 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17630 -> prob_abs_loss 0.009388864040374756 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17640 -> prob_abs_loss 0.009378790855407715 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17650 -> prob_abs_loss 0.009375333786010742 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17660 -> prob_abs_loss 0.009374141693115234 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 17670 -> prob_abs_loss 0.009373784065246582 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 17680 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17690 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 3.0\n",
      "Epoch 17700 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 6.0\n",
      "Epoch 17710 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 6.0\n",
      "Epoch 17720 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 7.0\n",
      "Epoch 17730 -> prob_abs_loss 0.00937354564666748 | sampled_mse_loss 4.0\n",
      "Epoch 17740 -> prob_abs_loss 0.009353876113891602 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 17750 -> prob_abs_loss 0.009322762489318848 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17760 -> prob_abs_loss 0.009312748908996582 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17770 -> prob_abs_loss 0.00930929183959961 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17780 -> prob_abs_loss 0.009308099746704102 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17790 -> prob_abs_loss 0.00930774211883545 | sampled_mse_loss 4.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17800 -> prob_abs_loss 0.009307622909545898 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 17810 -> prob_abs_loss 0.009259700775146484 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17820 -> prob_abs_loss 0.009227633476257324 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17830 -> prob_abs_loss 0.009217023849487305 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17840 -> prob_abs_loss 0.00921332836151123 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17850 -> prob_abs_loss 0.009212136268615723 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17860 -> prob_abs_loss 0.00921165943145752 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17870 -> prob_abs_loss 0.009211540222167969 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17880 -> prob_abs_loss 0.009211540222167969 | sampled_mse_loss 4.0\n",
      "Epoch 17890 -> prob_abs_loss 0.009211421012878418 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17900 -> prob_abs_loss 0.009199142456054688 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17910 -> prob_abs_loss 0.00918567180633545 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17920 -> prob_abs_loss 0.009164571762084961 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 17930 -> prob_abs_loss 0.009146571159362793 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17940 -> prob_abs_loss 0.009113729000091553 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 17950 -> prob_abs_loss 0.009103238582611084 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 17960 -> prob_abs_loss 0.009099781513214111 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 17970 -> prob_abs_loss 0.009098589420318604 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 17980 -> prob_abs_loss 0.009098231792449951 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 17990 -> prob_abs_loss 0.009068667888641357 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 18000 -> prob_abs_loss 0.009036123752593994 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18010 -> prob_abs_loss 0.009025752544403076 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 18020 -> prob_abs_loss 0.009022176265716553 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 18030 -> prob_abs_loss 0.009020984172821045 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18040 -> prob_abs_loss 0.009020507335662842 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 18050 -> prob_abs_loss 0.009020388126373291 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18060 -> prob_abs_loss 0.009020388126373291 | sampled_mse_loss 6.0\n",
      "Epoch 18070 -> prob_abs_loss 0.009020388126373291 | sampled_mse_loss 0.0\n",
      "Epoch 18080 -> prob_abs_loss 0.009020388126373291 | sampled_mse_loss 8.0\n",
      "Epoch 18090 -> prob_abs_loss 0.00902026891708374 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18100 -> prob_abs_loss 0.00902026891708374 | sampled_mse_loss 4.0\n",
      "Epoch 18110 -> prob_abs_loss 0.008966624736785889 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 18120 -> prob_abs_loss 0.008936882019042969 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18130 -> prob_abs_loss 0.008927106857299805 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18140 -> prob_abs_loss 0.008923768997192383 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 18150 -> prob_abs_loss 0.008922576904296875 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 18160 -> prob_abs_loss 0.008922219276428223 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18170 -> prob_abs_loss 0.008922100067138672 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 18180 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18190 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 3.0\n",
      "Epoch 18200 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 3.0\n",
      "Epoch 18210 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 5.0\n",
      "Epoch 18220 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 4.0\n",
      "Epoch 18230 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 4.0\n",
      "Epoch 18240 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 2.0\n",
      "Epoch 18250 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 2.0\n",
      "Epoch 18260 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 1.0\n",
      "Epoch 18270 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 6.0\n",
      "Epoch 18280 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 4.0\n",
      "Epoch 18290 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 7.0\n",
      "Epoch 18300 -> prob_abs_loss 0.008921980857849121 | sampled_mse_loss 3.0\n",
      "Epoch 18310 -> prob_abs_loss 0.008901536464691162 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 18320 -> prob_abs_loss 0.008884131908416748 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18330 -> prob_abs_loss 0.008878529071807861 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18340 -> prob_abs_loss 0.008876621723175049 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18350 -> prob_abs_loss 0.008876025676727295 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18360 -> prob_abs_loss 0.008842766284942627 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18370 -> prob_abs_loss 0.008825302124023438 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18380 -> prob_abs_loss 0.00881969928741455 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18390 -> prob_abs_loss 0.008817672729492188 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 18400 -> prob_abs_loss 0.008817076683044434 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18410 -> prob_abs_loss 0.008816838264465332 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18420 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18430 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 2.0\n",
      "Epoch 18440 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 4.0\n",
      "Epoch 18450 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 2.0\n",
      "Epoch 18460 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 0.0\n",
      "Epoch 18470 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 5.0\n",
      "Epoch 18480 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 4.0\n",
      "Epoch 18490 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 2.0\n",
      "Epoch 18500 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 4.0\n",
      "Epoch 18510 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 5.0\n",
      "Epoch 18520 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 2.0\n",
      "Epoch 18530 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 3.0\n",
      "Epoch 18540 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 6.0\n",
      "Epoch 18550 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 5.0\n",
      "Epoch 18560 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 4.0\n",
      "Epoch 18570 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 2.0\n",
      "Epoch 18580 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 1.0\n",
      "Epoch 18590 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 6.0\n",
      "Epoch 18600 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 8.0\n",
      "Epoch 18610 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 5.0\n",
      "Epoch 18620 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 1.0\n",
      "Epoch 18630 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 3.0\n",
      "Epoch 18640 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 3.0\n",
      "Epoch 18650 -> prob_abs_loss 0.008816719055175781 | sampled_mse_loss 6.0\n",
      "Epoch 18660 -> prob_abs_loss 0.008814692497253418 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18670 -> prob_abs_loss 0.008809208869934082 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 18680 -> prob_abs_loss 0.00880730152130127 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18690 -> prob_abs_loss 0.008806586265563965 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 18700 -> prob_abs_loss 0.008806347846984863 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 18710 -> prob_abs_loss 0.008806347846984863 | sampled_mse_loss 2.0\n",
      "Epoch 18720 -> prob_abs_loss 0.008806347846984863 | sampled_mse_loss 4.0\n",
      "Epoch 18730 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 18740 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 11.0\n",
      "Epoch 18750 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 9.0\n",
      "Epoch 18760 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18770 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 3.0\n",
      "Epoch 18780 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18790 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18800 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 1.0\n",
      "Epoch 18810 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 5.0\n",
      "Epoch 18820 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 1.0\n",
      "Epoch 18830 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 6.0\n",
      "Epoch 18840 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 2.0\n",
      "Epoch 18850 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18860 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18870 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 6.0\n",
      "Epoch 18880 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 3.0\n",
      "Epoch 18890 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 6.0\n",
      "Epoch 18900 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18910 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 12.0\n",
      "Epoch 18920 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 5.0\n",
      "Epoch 18930 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 6.0\n",
      "Epoch 18940 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18950 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 2.0\n",
      "Epoch 18960 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 4.0\n",
      "Epoch 18970 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 2.0\n",
      "Epoch 18980 -> prob_abs_loss 0.008806228637695312 | sampled_mse_loss 8.0\n",
      "Epoch 18990 -> prob_abs_loss 0.008783221244812012 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19000 -> prob_abs_loss 0.008745670318603516 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19010 -> prob_abs_loss 0.008721768856048584 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 19020 -> prob_abs_loss 0.008713901042938232 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19030 -> prob_abs_loss 0.008711159229278564 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19040 -> prob_abs_loss 0.008710324764251709 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 19050 -> prob_abs_loss 0.008709967136383057 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19060 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 19070 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19080 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19090 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 3.0\n",
      "Epoch 19100 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19110 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 3.0\n",
      "Epoch 19120 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 2.0\n",
      "Epoch 19130 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19140 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19150 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19160 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 6.0\n",
      "Epoch 19170 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19180 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 1.0\n",
      "Epoch 19190 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19200 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 7.0\n",
      "Epoch 19210 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19220 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19230 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 2.0\n",
      "Epoch 19240 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 1.0\n",
      "Epoch 19250 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 3.0\n",
      "Epoch 19260 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19270 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 7.0\n",
      "Epoch 19280 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 5.0\n",
      "Epoch 19290 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 2.0\n",
      "Epoch 19300 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19310 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 2.0\n",
      "Epoch 19320 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 4.0\n",
      "Epoch 19330 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 12.0\n",
      "Epoch 19340 -> prob_abs_loss 0.008709847927093506 | sampled_mse_loss 6.0\n",
      "Epoch 19350 -> prob_abs_loss 0.008687436580657959 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19360 -> prob_abs_loss 0.008679211139678955 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19370 -> prob_abs_loss 0.008676588535308838 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19380 -> prob_abs_loss 0.008675634860992432 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 19390 -> prob_abs_loss 0.00867527723312378 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 19400 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 19410 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 2.0\n",
      "Epoch 19420 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 1.0\n",
      "Epoch 19430 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 4.0\n",
      "Epoch 19440 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 6.0\n",
      "Epoch 19450 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 4.0\n",
      "Epoch 19460 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 3.0\n",
      "Epoch 19470 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 2.0\n",
      "Epoch 19480 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 4.0\n",
      "Epoch 19490 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 1.0\n",
      "Epoch 19500 -> prob_abs_loss 0.008675158023834229 | sampled_mse_loss 1.0\n",
      "Epoch 19510 -> prob_abs_loss 0.008663833141326904 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19520 -> prob_abs_loss 0.008635520935058594 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19530 -> prob_abs_loss 0.008626580238342285 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19540 -> prob_abs_loss 0.008623600006103516 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19550 -> prob_abs_loss 0.008596658706665039 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19560 -> prob_abs_loss 0.00857478380203247 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19570 -> prob_abs_loss 0.008567750453948975 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19580 -> prob_abs_loss 0.008565247058868408 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19590 -> prob_abs_loss 0.008552134037017822 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19600 -> prob_abs_loss 0.008495330810546875 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 19610 -> prob_abs_loss 0.00844264030456543 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 19620 -> prob_abs_loss 0.008398473262786865 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19630 -> prob_abs_loss 0.00838404893875122 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 19640 -> prob_abs_loss 0.008379161357879639 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 19650 -> prob_abs_loss 0.008377373218536377 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19660 -> prob_abs_loss 0.008376896381378174 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 19670 -> prob_abs_loss 0.008376657962799072 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 19680 -> prob_abs_loss 0.008376657962799072 | sampled_mse_loss 7.0\n",
      "Epoch 19690 -> prob_abs_loss 0.008376538753509521 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19700 -> prob_abs_loss 0.008366525173187256 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 19710 -> prob_abs_loss 0.008341312408447266 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19720 -> prob_abs_loss 0.008333444595336914 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19730 -> prob_abs_loss 0.008330702781677246 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 19740 -> prob_abs_loss 0.00832986831665039 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 19750 -> prob_abs_loss 0.00830984115600586 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 19760 -> prob_abs_loss 0.008301258087158203 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19770 -> prob_abs_loss 0.008298397064208984 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 19780 -> prob_abs_loss 0.008297443389892578 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 19790 -> prob_abs_loss 0.008296966552734375 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 19800 -> prob_abs_loss 0.008296847343444824 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 19810 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 19820 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 2.0\n",
      "Epoch 19830 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 4.0\n",
      "Epoch 19840 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 4.0\n",
      "Epoch 19850 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 8.0\n",
      "Epoch 19860 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 3.0\n",
      "Epoch 19870 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 5.0\n",
      "Epoch 19880 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 4.0\n",
      "Epoch 19890 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 3.0\n",
      "Epoch 19900 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 8.0\n",
      "Epoch 19910 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 5.0\n",
      "Epoch 19920 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 1.0\n",
      "Epoch 19930 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 2.0\n",
      "Epoch 19940 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 7.0\n",
      "Epoch 19950 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 4.0\n",
      "Epoch 19960 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19970 -> prob_abs_loss 0.008296728134155273 | sampled_mse_loss 4.0\n",
      "Epoch 19980 -> prob_abs_loss 0.008275210857391357 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 19990 -> prob_abs_loss 0.00825732946395874 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20000 -> prob_abs_loss 0.008251488208770752 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20010 -> prob_abs_loss 0.00824958086013794 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 20020 -> prob_abs_loss 0.008248865604400635 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20030 -> prob_abs_loss 0.008248627185821533 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20040 -> prob_abs_loss 0.008248507976531982 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20050 -> prob_abs_loss 0.008248507976531982 | sampled_mse_loss 2.0\n",
      "Epoch 20060 -> prob_abs_loss 0.008230984210968018 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 20070 -> prob_abs_loss 0.008211672306060791 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20080 -> prob_abs_loss 0.008178174495697021 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20090 -> prob_abs_loss 0.00816410779953003 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20100 -> prob_abs_loss 0.008159458637237549 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20110 -> prob_abs_loss 0.008157908916473389 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 20120 -> prob_abs_loss 0.008157312870025635 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20130 -> prob_abs_loss 0.008157193660736084 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20140 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20150 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 6.0\n",
      "Epoch 20160 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 4.0\n",
      "Epoch 20170 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 3.0\n",
      "Epoch 20180 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 1.0\n",
      "Epoch 20190 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 3.0\n",
      "Epoch 20200 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 3.0\n",
      "Epoch 20210 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 4.0\n",
      "Epoch 20220 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 4.0\n",
      "Epoch 20230 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 2.0\n",
      "Epoch 20240 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 1.0\n",
      "Epoch 20250 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 4.0\n",
      "Epoch 20260 -> prob_abs_loss 0.008157074451446533 | sampled_mse_loss 2.0\n",
      "Epoch 20270 -> prob_abs_loss 0.008144557476043701 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20280 -> prob_abs_loss 0.008125007152557373 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20290 -> prob_abs_loss 0.008118808269500732 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20300 -> prob_abs_loss 0.00811678171157837 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 20310 -> prob_abs_loss 0.008116066455841064 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20320 -> prob_abs_loss 0.008115828037261963 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 20330 -> prob_abs_loss 0.008115708827972412 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20340 -> prob_abs_loss 0.008115708827972412 | sampled_mse_loss 5.0\n",
      "Epoch 20350 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20360 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 7.0\n",
      "Epoch 20370 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 4.0\n",
      "Epoch 20380 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 6.0\n",
      "Epoch 20390 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 4.0\n",
      "Epoch 20400 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 6.0\n",
      "Epoch 20410 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 3.0\n",
      "Epoch 20420 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 2.0\n",
      "Epoch 20430 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 3.0\n",
      "Epoch 20440 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 3.0\n",
      "Epoch 20450 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 1.0\n",
      "Epoch 20460 -> prob_abs_loss 0.008115589618682861 | sampled_mse_loss 3.0\n",
      "Epoch 20470 -> prob_abs_loss 0.008071601390838623 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20480 -> prob_abs_loss 0.008048474788665771 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20490 -> prob_abs_loss 0.008040845394134521 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20500 -> prob_abs_loss 0.008038222789764404 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20510 -> prob_abs_loss 0.008013546466827393 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20520 -> prob_abs_loss 0.007993340492248535 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20530 -> prob_abs_loss 0.007972121238708496 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20540 -> prob_abs_loss 0.00793302059173584 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 20550 -> prob_abs_loss 0.00792086124420166 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20560 -> prob_abs_loss 0.007916688919067383 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20570 -> prob_abs_loss 0.007915258407592773 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20580 -> prob_abs_loss 0.00791478157043457 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20590 -> prob_abs_loss 0.00791466236114502 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20600 -> prob_abs_loss 0.007914543151855469 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 20610 -> prob_abs_loss 0.007914543151855469 | sampled_mse_loss 9.0\n",
      "Epoch 20620 -> prob_abs_loss 0.007914543151855469 | sampled_mse_loss 5.0\n",
      "Epoch 20630 -> prob_abs_loss 0.00789940357208252 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20640 -> prob_abs_loss 0.007886886596679688 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20650 -> prob_abs_loss 0.007882833480834961 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20660 -> prob_abs_loss 0.007881522178649902 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20670 -> prob_abs_loss 0.0078810453414917 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20680 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20690 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 5.0\n",
      "Epoch 20700 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 1.0\n",
      "Epoch 20710 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 11.0\n",
      "Epoch 20720 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 6.0\n",
      "Epoch 20730 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 4.0\n",
      "Epoch 20740 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 14.0\n",
      "Epoch 20750 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 1.0\n",
      "Epoch 20760 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 10.0\n",
      "Epoch 20770 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 2.0\n",
      "Epoch 20780 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 7.0\n",
      "Epoch 20790 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 4.0\n",
      "Epoch 20800 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 6.0\n",
      "Epoch 20810 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 3.0\n",
      "Epoch 20820 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 4.0\n",
      "Epoch 20830 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 5.0\n",
      "Epoch 20840 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 2.0\n",
      "Epoch 20850 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 6.0\n",
      "Epoch 20860 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 1.0\n",
      "Epoch 20870 -> prob_abs_loss 0.007880806922912598 | sampled_mse_loss 4.0\n",
      "Epoch 20880 -> prob_abs_loss 0.007861137390136719 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 20890 -> prob_abs_loss 0.007847785949707031 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20900 -> prob_abs_loss 0.007843375205993652 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20910 -> prob_abs_loss 0.007841885089874268 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 20920 -> prob_abs_loss 0.007841289043426514 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 20930 -> prob_abs_loss 0.007825613021850586 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 20940 -> prob_abs_loss 0.007820367813110352 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20950 -> prob_abs_loss 0.00781857967376709 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 20960 -> prob_abs_loss 0.007817983627319336 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20970 -> prob_abs_loss 0.007817745208740234 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 20980 -> prob_abs_loss 0.007817625999450684 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 20990 -> prob_abs_loss 0.007817625999450684 | sampled_mse_loss 2.0\n",
      "Epoch 21000 -> prob_abs_loss 0.007817625999450684 | sampled_mse_loss 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21010 -> prob_abs_loss 0.007817625999450684 | sampled_mse_loss 7.0\n",
      "Epoch 21020 -> prob_abs_loss 0.007782280445098877 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 21030 -> prob_abs_loss 0.007769525051116943 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 21040 -> prob_abs_loss 0.007765233516693115 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21050 -> prob_abs_loss 0.007763803005218506 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 21060 -> prob_abs_loss 0.007763326168060303 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21070 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21080 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 3.0\n",
      "Epoch 21090 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 3.0\n",
      "Epoch 21100 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 1.0\n",
      "Epoch 21110 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 2.0\n",
      "Epoch 21120 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21130 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 9.0\n",
      "Epoch 21140 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21150 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21160 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 2.0\n",
      "Epoch 21170 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 11.0\n",
      "Epoch 21180 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21190 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 3.0\n",
      "Epoch 21200 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 11.0\n",
      "Epoch 21210 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 2.0\n",
      "Epoch 21220 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 4.0\n",
      "Epoch 21230 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 3.0\n",
      "Epoch 21240 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21250 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 6.0\n",
      "Epoch 21260 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 2.0\n",
      "Epoch 21270 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 7.0\n",
      "Epoch 21280 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 4.0\n",
      "Epoch 21290 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 4.0\n",
      "Epoch 21300 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 6.0\n",
      "Epoch 21310 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 4.0\n",
      "Epoch 21320 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21330 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 5.0\n",
      "Epoch 21340 -> prob_abs_loss 0.007763087749481201 | sampled_mse_loss 2.0\n",
      "Epoch 21350 -> prob_abs_loss 0.007749736309051514 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 21360 -> prob_abs_loss 0.0077165961265563965 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21370 -> prob_abs_loss 0.007694244384765625 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21380 -> prob_abs_loss 0.007671713829040527 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21390 -> prob_abs_loss 0.007658839225769043 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 21400 -> prob_abs_loss 0.007626235485076904 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 21410 -> prob_abs_loss 0.007615983486175537 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21420 -> prob_abs_loss 0.0076125264167785645 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21430 -> prob_abs_loss 0.007611334323883057 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21440 -> prob_abs_loss 0.007604539394378662 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 21450 -> prob_abs_loss 0.007588326930999756 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21460 -> prob_abs_loss 0.007583320140838623 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21470 -> prob_abs_loss 0.0075814127922058105 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21480 -> prob_abs_loss 0.007580816745758057 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21490 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21500 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 4.0\n",
      "Epoch 21510 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21520 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 4.0\n",
      "Epoch 21530 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21540 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 1.0\n",
      "Epoch 21550 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21560 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 5.0\n",
      "Epoch 21570 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21580 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 3.0\n",
      "Epoch 21590 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21600 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21610 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 4.0\n",
      "Epoch 21620 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21630 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 5.0\n",
      "Epoch 21640 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21650 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 5.0\n",
      "Epoch 21660 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 5.0\n",
      "Epoch 21670 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21680 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 5.0\n",
      "Epoch 21690 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21700 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 3.0\n",
      "Epoch 21710 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21720 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 2.0\n",
      "Epoch 21730 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 6.0\n",
      "Epoch 21740 -> prob_abs_loss 0.007580578327178955 | sampled_mse_loss 7.0\n",
      "Epoch 21750 -> prob_abs_loss 0.007575690746307373 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21760 -> prob_abs_loss 0.007550179958343506 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21770 -> prob_abs_loss 0.0075421929359436035 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21780 -> prob_abs_loss 0.007539570331573486 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 21790 -> prob_abs_loss 0.00753861665725708 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21800 -> prob_abs_loss 0.0075383782386779785 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21810 -> prob_abs_loss 0.007538259029388428 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 21820 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21830 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 3.0\n",
      "Epoch 21840 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 5.0\n",
      "Epoch 21850 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 4.0\n",
      "Epoch 21860 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 1.0\n",
      "Epoch 21870 -> prob_abs_loss 0.007538139820098877 | sampled_mse_loss 5.0\n",
      "Epoch 21880 -> prob_abs_loss 0.007520139217376709 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21890 -> prob_abs_loss 0.007508337497711182 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21900 -> prob_abs_loss 0.007504522800445557 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21910 -> prob_abs_loss 0.007503211498260498 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21920 -> prob_abs_loss 0.007502734661102295 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 21930 -> prob_abs_loss 0.007502496242523193 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21940 -> prob_abs_loss 0.007502496242523193 | sampled_mse_loss 3.0\n",
      "Epoch 21950 -> prob_abs_loss 0.007497608661651611 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21960 -> prob_abs_loss 0.0074898600578308105 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 21970 -> prob_abs_loss 0.007487237453460693 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 21980 -> prob_abs_loss 0.007486402988433838 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 21990 -> prob_abs_loss 0.0074860453605651855 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22000 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22010 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 5.0\n",
      "Epoch 22020 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 6.0\n",
      "Epoch 22030 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 3.0\n",
      "Epoch 22040 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 4.0\n",
      "Epoch 22050 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 1.0\n",
      "Epoch 22060 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 4.0\n",
      "Epoch 22070 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 7.0\n",
      "Epoch 22080 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 8.0\n",
      "Epoch 22090 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 5.0\n",
      "Epoch 22100 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 4.0\n",
      "Epoch 22110 -> prob_abs_loss 0.007485926151275635 | sampled_mse_loss 4.0\n",
      "Epoch 22120 -> prob_abs_loss 0.007477700710296631 | sampled_mse_loss 3.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22130 -> prob_abs_loss 0.0074043869972229 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 22140 -> prob_abs_loss 0.007366001605987549 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22150 -> prob_abs_loss 0.007353544235229492 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 22160 -> prob_abs_loss 0.0073490142822265625 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22170 -> prob_abs_loss 0.007347702980041504 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22180 -> prob_abs_loss 0.00734710693359375 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22190 -> prob_abs_loss 0.0073468685150146484 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22200 -> prob_abs_loss 0.0073403120040893555 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 22210 -> prob_abs_loss 0.00730520486831665 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22220 -> prob_abs_loss 0.007294356822967529 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22230 -> prob_abs_loss 0.007290661334991455 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22240 -> prob_abs_loss 0.007289469242095947 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22250 -> prob_abs_loss 0.007288992404937744 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 22260 -> prob_abs_loss 0.007288873195648193 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22270 -> prob_abs_loss 0.007288873195648193 | sampled_mse_loss 5.0\n",
      "Epoch 22280 -> prob_abs_loss 0.007288753986358643 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22290 -> prob_abs_loss 0.007288753986358643 | sampled_mse_loss 3.0\n",
      "Epoch 22300 -> prob_abs_loss 0.007288753986358643 | sampled_mse_loss 1.0\n",
      "Epoch 22310 -> prob_abs_loss 0.007282555103302002 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22320 -> prob_abs_loss 0.007278382778167725 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 22330 -> prob_abs_loss 0.007276952266693115 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 22340 -> prob_abs_loss 0.007276356220245361 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22350 -> prob_abs_loss 0.0072762370109558105 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 22360 -> prob_abs_loss 0.00727611780166626 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22370 -> prob_abs_loss 0.00727611780166626 | sampled_mse_loss 4.0\n",
      "Epoch 22380 -> prob_abs_loss 0.00727611780166626 | sampled_mse_loss 2.0\n",
      "Epoch 22390 -> prob_abs_loss 0.00727611780166626 | sampled_mse_loss 11.0\n",
      "Epoch 22400 -> prob_abs_loss 0.00727611780166626 | sampled_mse_loss 6.0\n",
      "Epoch 22410 -> prob_abs_loss 0.0072661638259887695 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 22420 -> prob_abs_loss 0.007241368293762207 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22430 -> prob_abs_loss 0.007233619689941406 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 22440 -> prob_abs_loss 0.007230997085571289 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22450 -> prob_abs_loss 0.007230043411254883 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22460 -> prob_abs_loss 0.007229804992675781 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22470 -> prob_abs_loss 0.0072296857833862305 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22480 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 22490 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 7.0\n",
      "Epoch 22500 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 5.0\n",
      "Epoch 22510 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 3.0\n",
      "Epoch 22520 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 3.0\n",
      "Epoch 22530 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 3.0\n",
      "Epoch 22540 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 5.0\n",
      "Epoch 22550 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 2.0\n",
      "Epoch 22560 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 2.0\n",
      "Epoch 22570 -> prob_abs_loss 0.00722956657409668 | sampled_mse_loss 3.0\n",
      "Epoch 22580 -> prob_abs_loss 0.007217049598693848 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22590 -> prob_abs_loss 0.007184386253356934 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22600 -> prob_abs_loss 0.007166504859924316 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22610 -> prob_abs_loss 0.007160663604736328 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22620 -> prob_abs_loss 0.007158637046813965 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22630 -> prob_abs_loss 0.007158041000366211 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 22640 -> prob_abs_loss 0.007157683372497559 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 22650 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 22660 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 5.0\n",
      "Epoch 22670 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 5.0\n",
      "Epoch 22680 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 3.0\n",
      "Epoch 22690 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 5.0\n",
      "Epoch 22700 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 11.0\n",
      "Epoch 22710 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 2.0\n",
      "Epoch 22720 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 8.0\n",
      "Epoch 22730 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 5.0\n",
      "Epoch 22740 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 2.0\n",
      "Epoch 22750 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 9.0\n",
      "Epoch 22760 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 4.0\n",
      "Epoch 22770 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 6.0\n",
      "Epoch 22780 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 3.0\n",
      "Epoch 22790 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 4.0\n",
      "Epoch 22800 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 1.0\n",
      "Epoch 22810 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 3.0\n",
      "Epoch 22820 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 4.0\n",
      "Epoch 22830 -> prob_abs_loss 0.007157564163208008 | sampled_mse_loss 0.0\n",
      "Epoch 22840 -> prob_abs_loss 0.007146477699279785 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 22850 -> prob_abs_loss 0.007082641124725342 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 22860 -> prob_abs_loss 0.007051527500152588 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22870 -> prob_abs_loss 0.007041275501251221 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 22880 -> prob_abs_loss 0.007037699222564697 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 22890 -> prob_abs_loss 0.007036387920379639 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 22900 -> prob_abs_loss 0.007036030292510986 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22910 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 22920 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 3.0\n",
      "Epoch 22930 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 3.0\n",
      "Epoch 22940 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 3.0\n",
      "Epoch 22950 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 5.0\n",
      "Epoch 22960 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 9.0\n",
      "Epoch 22970 -> prob_abs_loss 0.0070359110832214355 | sampled_mse_loss 4.0\n",
      "Epoch 22980 -> prob_abs_loss 0.006995737552642822 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 22990 -> prob_abs_loss 0.006978452205657959 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23000 -> prob_abs_loss 0.0069727301597595215 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 23010 -> prob_abs_loss 0.006970822811126709 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 23020 -> prob_abs_loss 0.006970107555389404 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 23030 -> prob_abs_loss 0.006969869136810303 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23040 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 23050 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 2.0\n",
      "Epoch 23060 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n",
      "Epoch 23070 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n",
      "Epoch 23080 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 6.0\n",
      "Epoch 23090 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 5.0\n",
      "Epoch 23100 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23110 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 5.0\n",
      "Epoch 23120 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n",
      "Epoch 23130 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 2.0\n",
      "Epoch 23140 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23150 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n",
      "Epoch 23160 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 8.0\n",
      "Epoch 23170 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23180 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 6.0\n",
      "Epoch 23190 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 5.0\n",
      "Epoch 23200 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23210 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 2.0\n",
      "Epoch 23220 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 10.0\n",
      "Epoch 23230 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 4.0\n",
      "Epoch 23240 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 0.0\n",
      "Epoch 23250 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23260 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 7.0\n",
      "Epoch 23270 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 2.0\n",
      "Epoch 23280 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 1.0\n",
      "Epoch 23290 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 4.0\n",
      "Epoch 23300 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23310 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 7.0\n",
      "Epoch 23320 -> prob_abs_loss 0.006969749927520752 | sampled_mse_loss 3.0\n",
      "Epoch 23330 -> prob_abs_loss 0.0069547295570373535 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23340 -> prob_abs_loss 0.00694805383682251 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 23350 -> prob_abs_loss 0.006945788860321045 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23360 -> prob_abs_loss 0.0069449543952941895 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23370 -> prob_abs_loss 0.006944715976715088 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 23380 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 23390 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 2.0\n",
      "Epoch 23400 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 3.0\n",
      "Epoch 23410 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 6.0\n",
      "Epoch 23420 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 2.0\n",
      "Epoch 23430 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 5.0\n",
      "Epoch 23440 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 3.0\n",
      "Epoch 23450 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 7.0\n",
      "Epoch 23460 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 5.0\n",
      "Epoch 23470 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 2.0\n",
      "Epoch 23480 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 4.0\n",
      "Epoch 23490 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 2.0\n",
      "Epoch 23500 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 9.0\n",
      "Epoch 23510 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 1.0\n",
      "Epoch 23520 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 2.0\n",
      "Epoch 23530 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 4.0\n",
      "Epoch 23540 -> prob_abs_loss 0.006944596767425537 | sampled_mse_loss 4.0\n",
      "Epoch 23550 -> prob_abs_loss 0.006921291351318359 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23560 -> prob_abs_loss 0.006901860237121582 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 23570 -> prob_abs_loss 0.006895542144775391 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 23580 -> prob_abs_loss 0.0068933963775634766 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 23590 -> prob_abs_loss 0.006892681121826172 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 23600 -> prob_abs_loss 0.00689244270324707 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 23610 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 23620 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23630 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23640 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 4.0\n",
      "Epoch 23650 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23660 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 2.0\n",
      "Epoch 23670 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 8.0\n",
      "Epoch 23680 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 4.0\n",
      "Epoch 23690 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 5.0\n",
      "Epoch 23700 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 2.0\n",
      "Epoch 23710 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 1.0\n",
      "Epoch 23720 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 5.0\n",
      "Epoch 23730 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 1.0\n",
      "Epoch 23740 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 4.0\n",
      "Epoch 23750 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 6.0\n",
      "Epoch 23760 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 4.0\n",
      "Epoch 23770 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 4.0\n",
      "Epoch 23780 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23790 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 7.0\n",
      "Epoch 23800 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 6.0\n",
      "Epoch 23810 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 6.0\n",
      "Epoch 23820 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 6.0\n",
      "Epoch 23830 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 2.0\n",
      "Epoch 23840 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 7.0\n",
      "Epoch 23850 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 7.0\n",
      "Epoch 23860 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23870 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23880 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 7.0\n",
      "Epoch 23890 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23900 -> prob_abs_loss 0.0068923234939575195 | sampled_mse_loss 3.0\n",
      "Epoch 23910 -> prob_abs_loss 0.006855130195617676 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 23920 -> prob_abs_loss 0.0068392157554626465 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 23930 -> prob_abs_loss 0.006833851337432861 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 23940 -> prob_abs_loss 0.0068320631980896 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 23950 -> prob_abs_loss 0.006831467151641846 | sampled_mse_loss 11.0\n",
      "Model saved\n",
      "Epoch 23960 -> prob_abs_loss 0.006831228733062744 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 23970 -> prob_abs_loss 0.006812989711761475 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 23980 -> prob_abs_loss 0.006805241107940674 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 23990 -> prob_abs_loss 0.006802618503570557 | sampled_mse_loss 10.0\n",
      "Model saved\n",
      "Epoch 24000 -> prob_abs_loss 0.006801784038543701 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24010 -> prob_abs_loss 0.006801426410675049 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24020 -> prob_abs_loss 0.006801307201385498 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24030 -> prob_abs_loss 0.006801307201385498 | sampled_mse_loss 1.0\n",
      "Epoch 24040 -> prob_abs_loss 0.0067803263664245605 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 24050 -> prob_abs_loss 0.0067476630210876465 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24060 -> prob_abs_loss 0.0067372918128967285 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 24070 -> prob_abs_loss 0.006733834743499756 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24080 -> prob_abs_loss 0.006732642650604248 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 24090 -> prob_abs_loss 0.006732165813446045 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24100 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 24110 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 3.0\n",
      "Epoch 24120 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 6.0\n",
      "Epoch 24130 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 4.0\n",
      "Epoch 24140 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 6.0\n",
      "Epoch 24150 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 5.0\n",
      "Epoch 24160 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 5.0\n",
      "Epoch 24170 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 4.0\n",
      "Epoch 24180 -> prob_abs_loss 0.006732046604156494 | sampled_mse_loss 2.0\n",
      "Epoch 24190 -> prob_abs_loss 0.006727159023284912 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24200 -> prob_abs_loss 0.006701529026031494 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 24210 -> prob_abs_loss 0.006667912006378174 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24220 -> prob_abs_loss 0.0066435933113098145 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24230 -> prob_abs_loss 0.006635606288909912 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24240 -> prob_abs_loss 0.006632745265960693 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 24250 -> prob_abs_loss 0.006631791591644287 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 24260 -> prob_abs_loss 0.0066315531730651855 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24270 -> prob_abs_loss 0.006631433963775635 | sampled_mse_loss 3.0\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24280 -> prob_abs_loss 0.006631314754486084 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 24290 -> prob_abs_loss 0.006631314754486084 | sampled_mse_loss 7.0\n",
      "Epoch 24300 -> prob_abs_loss 0.006631314754486084 | sampled_mse_loss 4.0\n",
      "Epoch 24310 -> prob_abs_loss 0.006631314754486084 | sampled_mse_loss 2.0\n",
      "Epoch 24320 -> prob_abs_loss 0.006618916988372803 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24330 -> prob_abs_loss 0.006599485874176025 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24340 -> prob_abs_loss 0.006593286991119385 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24350 -> prob_abs_loss 0.0065912604331970215 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 24360 -> prob_abs_loss 0.006585657596588135 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 24370 -> prob_abs_loss 0.00657278299331665 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 24380 -> prob_abs_loss 0.006568610668182373 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24390 -> prob_abs_loss 0.0065672993659973145 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 24400 -> prob_abs_loss 0.006566822528839111 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24410 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 24420 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24430 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 6.0\n",
      "Epoch 24440 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24450 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 1.0\n",
      "Epoch 24460 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 5.0\n",
      "Epoch 24470 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 2.0\n",
      "Epoch 24480 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 2.0\n",
      "Epoch 24490 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 5.0\n",
      "Epoch 24500 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 2.0\n",
      "Epoch 24510 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 4.0\n",
      "Epoch 24520 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24530 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 6.0\n",
      "Epoch 24540 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 4.0\n",
      "Epoch 24550 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 6.0\n",
      "Epoch 24560 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24570 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 8.0\n",
      "Epoch 24580 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24590 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 6.0\n",
      "Epoch 24600 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 4.0\n",
      "Epoch 24610 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 5.0\n",
      "Epoch 24620 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 12.0\n",
      "Epoch 24630 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 7.0\n",
      "Epoch 24640 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 2.0\n",
      "Epoch 24650 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24660 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 3.0\n",
      "Epoch 24670 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 4.0\n",
      "Epoch 24680 -> prob_abs_loss 0.00656658411026001 | sampled_mse_loss 5.0\n",
      "Epoch 24690 -> prob_abs_loss 0.006539702415466309 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 24700 -> prob_abs_loss 0.006529688835144043 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24710 -> prob_abs_loss 0.006526350975036621 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 24720 -> prob_abs_loss 0.006525158882141113 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 24730 -> prob_abs_loss 0.006524801254272461 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 24740 -> prob_abs_loss 0.00652468204498291 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 24750 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 24760 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 24770 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 24780 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 5.0\n",
      "Epoch 24790 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24800 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 24810 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24820 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 1.0\n",
      "Epoch 24830 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 24840 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 7.0\n",
      "Epoch 24850 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24860 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 24870 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Epoch 24880 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 1.0\n",
      "Epoch 24890 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 24900 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 24910 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 5.0\n",
      "Epoch 24920 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 24930 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24940 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24950 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 0.0\n",
      "Epoch 24960 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 24970 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Epoch 24980 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 24990 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 5.0\n",
      "Epoch 25000 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 25010 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 25020 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Epoch 25030 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Epoch 25040 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 5.0\n",
      "Epoch 25050 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 1.0\n",
      "Epoch 25060 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 12.0\n",
      "Epoch 25070 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 7.0\n",
      "Epoch 25080 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 4.0\n",
      "Epoch 25090 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 6.0\n",
      "Epoch 25100 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 1.0\n",
      "Epoch 25110 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 12.0\n",
      "Epoch 25120 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 25130 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 25140 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 5.0\n",
      "Epoch 25150 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 7.0\n",
      "Epoch 25160 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 2.0\n",
      "Epoch 25170 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 3.0\n",
      "Epoch 25180 -> prob_abs_loss 0.006524562835693359 | sampled_mse_loss 1.0\n",
      "Epoch 25190 -> prob_abs_loss 0.0065059661865234375 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 25200 -> prob_abs_loss 0.006490468978881836 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 25210 -> prob_abs_loss 0.006485462188720703 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 25220 -> prob_abs_loss 0.006483793258666992 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 25230 -> prob_abs_loss 0.006483197212219238 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 25240 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 25250 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 8.0\n",
      "Epoch 25260 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25270 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25280 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25290 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25300 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25310 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25320 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 7.0\n",
      "Epoch 25330 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25340 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 2.0\n",
      "Epoch 25350 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 1.0\n",
      "Epoch 25360 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25370 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25380 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25390 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25400 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25410 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 8.0\n",
      "Epoch 25420 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 1.0\n",
      "Epoch 25430 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25440 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25450 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25460 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 12.0\n",
      "Epoch 25470 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 9.0\n",
      "Epoch 25480 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25490 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 4.0\n",
      "Epoch 25500 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 2.0\n",
      "Epoch 25510 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 6.0\n",
      "Epoch 25520 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 2.0\n",
      "Epoch 25530 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 9.0\n",
      "Epoch 25540 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25550 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 5.0\n",
      "Epoch 25560 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 3.0\n",
      "Epoch 25570 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 7.0\n",
      "Epoch 25580 -> prob_abs_loss 0.006482958793640137 | sampled_mse_loss 7.0\n",
      "Epoch 25590 -> prob_abs_loss 0.006467103958129883 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 25600 -> prob_abs_loss 0.006456851959228516 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 25610 -> prob_abs_loss 0.006453514099121094 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 25620 -> prob_abs_loss 0.006452322006225586 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 25630 -> prob_abs_loss 0.006451964378356934 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 25640 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 25650 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Epoch 25660 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 6.0\n",
      "Epoch 25670 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25680 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 6.0\n",
      "Epoch 25690 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Epoch 25700 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 1.0\n",
      "Epoch 25710 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25720 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 25730 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 6.0\n",
      "Epoch 25740 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 25750 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 25760 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 25770 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 25780 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 25790 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 1.0\n",
      "Epoch 25800 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 8.0\n",
      "Epoch 25810 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 7.0\n",
      "Epoch 25820 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 25830 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 25840 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 6.0\n",
      "Epoch 25850 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 1.0\n",
      "Epoch 25860 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 7.0\n",
      "Epoch 25870 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25880 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25890 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 6.0\n",
      "Epoch 25900 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 7.0\n",
      "Epoch 25910 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 25920 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 1.0\n",
      "Epoch 25930 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25940 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 7.0\n",
      "Epoch 25950 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25960 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 25970 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 25980 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Epoch 25990 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 26000 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 5.0\n",
      "Epoch 26010 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Epoch 26020 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 26030 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 26040 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 8.0\n",
      "Epoch 26050 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 4.0\n",
      "Epoch 26060 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 26070 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 8.0\n",
      "Epoch 26080 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 26090 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 26100 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 3.0\n",
      "Epoch 26110 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 2.0\n",
      "Epoch 26120 -> prob_abs_loss 0.006451725959777832 | sampled_mse_loss 8.0\n",
      "Epoch 26130 -> prob_abs_loss 0.00644683837890625 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 26140 -> prob_abs_loss 0.006421208381652832 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 26150 -> prob_abs_loss 0.00641322135925293 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 26160 -> prob_abs_loss 0.006410479545593262 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 26170 -> prob_abs_loss 0.0064095258712768555 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 26180 -> prob_abs_loss 0.006409287452697754 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26190 -> prob_abs_loss 0.006409168243408203 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26200 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 26210 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 1.0\n",
      "Epoch 26220 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 6.0\n",
      "Epoch 26230 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 1.0\n",
      "Epoch 26240 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 6.0\n",
      "Epoch 26250 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 4.0\n",
      "Epoch 26260 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 2.0\n",
      "Epoch 26270 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 5.0\n",
      "Epoch 26280 -> prob_abs_loss 0.006409049034118652 | sampled_mse_loss 9.0\n",
      "Epoch 26290 -> prob_abs_loss 0.0063860416412353516 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 26300 -> prob_abs_loss 0.006329178810119629 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 26310 -> prob_abs_loss 0.006311297416687012 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26320 -> prob_abs_loss 0.006293892860412598 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26330 -> prob_abs_loss 0.006268501281738281 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 26340 -> prob_abs_loss 0.006253838539123535 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26350 -> prob_abs_loss 0.006249070167541504 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 26360 -> prob_abs_loss 0.006247520446777344 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 26370 -> prob_abs_loss 0.00624692440032959 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 26380 -> prob_abs_loss 0.006246805191040039 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 26390 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 26400 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 7.0\n",
      "Epoch 26410 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 6.0\n",
      "Epoch 26420 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 1.0\n",
      "Epoch 26430 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 2.0\n",
      "Epoch 26440 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 3.0\n",
      "Epoch 26450 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26460 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 2.0\n",
      "Epoch 26470 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 2.0\n",
      "Epoch 26480 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 6.0\n",
      "Epoch 26490 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 7.0\n",
      "Epoch 26500 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26510 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 4.0\n",
      "Epoch 26520 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26530 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26540 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26550 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 3.0\n",
      "Epoch 26560 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 4.0\n",
      "Epoch 26570 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 2.0\n",
      "Epoch 26580 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 1.0\n",
      "Epoch 26590 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 3.0\n",
      "Epoch 26600 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 4.0\n",
      "Epoch 26610 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26620 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 4.0\n",
      "Epoch 26630 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 3.0\n",
      "Epoch 26640 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 3.0\n",
      "Epoch 26650 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26660 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 5.0\n",
      "Epoch 26670 -> prob_abs_loss 0.006246685981750488 | sampled_mse_loss 1.0\n",
      "Epoch 26680 -> prob_abs_loss 0.006226658821105957 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26690 -> prob_abs_loss 0.006220579147338867 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 26700 -> prob_abs_loss 0.006218552589416504 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 26710 -> prob_abs_loss 0.006217837333679199 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 26720 -> prob_abs_loss 0.006217598915100098 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26730 -> prob_abs_loss 0.006217598915100098 | sampled_mse_loss 1.0\n",
      "Epoch 26740 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26750 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 3.0\n",
      "Epoch 26760 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 4.0\n",
      "Epoch 26770 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 6.0\n",
      "Epoch 26780 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 6.0\n",
      "Epoch 26790 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 3.0\n",
      "Epoch 26800 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 5.0\n",
      "Epoch 26810 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 5.0\n",
      "Epoch 26820 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 1.0\n",
      "Epoch 26830 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 2.0\n",
      "Epoch 26840 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 1.0\n",
      "Epoch 26850 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 6.0\n",
      "Epoch 26860 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 1.0\n",
      "Epoch 26870 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 4.0\n",
      "Epoch 26880 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 3.0\n",
      "Epoch 26890 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 3.0\n",
      "Epoch 26900 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 1.0\n",
      "Epoch 26910 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 3.0\n",
      "Epoch 26920 -> prob_abs_loss 0.006217479705810547 | sampled_mse_loss 5.0\n",
      "Epoch 26930 -> prob_abs_loss 0.006195783615112305 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 26940 -> prob_abs_loss 0.0061817169189453125 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 26950 -> prob_abs_loss 0.006177067756652832 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 26960 -> prob_abs_loss 0.006175518035888672 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 26970 -> prob_abs_loss 0.006174921989440918 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 26980 -> prob_abs_loss 0.006174802780151367 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 26990 -> prob_abs_loss 0.006174683570861816 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27000 -> prob_abs_loss 0.006160378456115723 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 27010 -> prob_abs_loss 0.0061244964599609375 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27020 -> prob_abs_loss 0.006113409996032715 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27030 -> prob_abs_loss 0.00610959529876709 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27040 -> prob_abs_loss 0.006108283996582031 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 27050 -> prob_abs_loss 0.006107807159423828 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 27060 -> prob_abs_loss 0.006107687950134277 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27070 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 27080 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 2.0\n",
      "Epoch 27090 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 4.0\n",
      "Epoch 27100 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 3.0\n",
      "Epoch 27110 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 0.0\n",
      "Epoch 27120 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 6.0\n",
      "Epoch 27130 -> prob_abs_loss 0.0061075687408447266 | sampled_mse_loss 10.0\n",
      "Epoch 27140 -> prob_abs_loss 0.006099581718444824 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27150 -> prob_abs_loss 0.006086945533752441 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27160 -> prob_abs_loss 0.006083011627197266 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 27170 -> prob_abs_loss 0.006081700325012207 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27180 -> prob_abs_loss 0.006081223487854004 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 27190 -> prob_abs_loss 0.006080985069274902 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27200 -> prob_abs_loss 0.006080985069274902 | sampled_mse_loss 6.0\n",
      "Epoch 27210 -> prob_abs_loss 0.006080985069274902 | sampled_mse_loss 5.0\n",
      "Epoch 27220 -> prob_abs_loss 0.006080985069274902 | sampled_mse_loss 3.0\n",
      "Epoch 27230 -> prob_abs_loss 0.006080985069274902 | sampled_mse_loss 4.0\n",
      "Epoch 27240 -> prob_abs_loss 0.006062984466552734 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 27250 -> prob_abs_loss 0.0060346126556396484 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 27260 -> prob_abs_loss 0.006025731563568115 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27270 -> prob_abs_loss 0.006022751331329346 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 27280 -> prob_abs_loss 0.006021678447723389 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27290 -> prob_abs_loss 0.006021320819854736 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27300 -> prob_abs_loss 0.0060212016105651855 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27310 -> prob_abs_loss 0.0060212016105651855 | sampled_mse_loss 3.0\n",
      "Epoch 27320 -> prob_abs_loss 0.0060212016105651855 | sampled_mse_loss 4.0\n",
      "Epoch 27330 -> prob_abs_loss 0.0060212016105651855 | sampled_mse_loss 4.0\n",
      "Epoch 27340 -> prob_abs_loss 0.0060212016105651855 | sampled_mse_loss 1.0\n",
      "Epoch 27350 -> prob_abs_loss 0.006016075611114502 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27360 -> prob_abs_loss 0.006007969379425049 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27370 -> prob_abs_loss 0.006005465984344482 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 27380 -> prob_abs_loss 0.006004512310028076 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 27390 -> prob_abs_loss 0.006004273891448975 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 27400 -> prob_abs_loss 0.006004154682159424 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 27410 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 27420 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 5.0\n",
      "Epoch 27430 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 5.0\n",
      "Epoch 27440 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 4.0\n",
      "Epoch 27450 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 3.0\n",
      "Epoch 27460 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 4.0\n",
      "Epoch 27470 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 7.0\n",
      "Epoch 27480 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 2.0\n",
      "Epoch 27490 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 7.0\n",
      "Epoch 27500 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 4.0\n",
      "Epoch 27510 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 2.0\n",
      "Epoch 27520 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 6.0\n",
      "Epoch 27530 -> prob_abs_loss 0.006004035472869873 | sampled_mse_loss 2.0\n",
      "Epoch 27540 -> prob_abs_loss 0.005987584590911865 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27550 -> prob_abs_loss 0.005973875522613525 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 27560 -> prob_abs_loss 0.0059694647789001465 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27570 -> prob_abs_loss 0.005967915058135986 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 27580 -> prob_abs_loss 0.005967438220977783 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27590 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 27600 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 1.0\n",
      "Epoch 27610 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27620 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27630 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27640 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27650 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27660 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27670 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27680 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27690 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27700 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27710 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 6.0\n",
      "Epoch 27720 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27730 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27740 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27750 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27760 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27770 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27780 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27790 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 2.0\n",
      "Epoch 27800 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27810 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 6.0\n",
      "Epoch 27820 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27830 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27840 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 5.0\n",
      "Epoch 27850 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 6.0\n",
      "Epoch 27860 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27870 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 2.0\n",
      "Epoch 27880 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 12.0\n",
      "Epoch 27890 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 4.0\n",
      "Epoch 27900 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27910 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27920 -> prob_abs_loss 0.005967199802398682 | sampled_mse_loss 3.0\n",
      "Epoch 27930 -> prob_abs_loss 0.005938231945037842 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 27940 -> prob_abs_loss 0.005919337272644043 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 27950 -> prob_abs_loss 0.005913257598876953 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 27960 -> prob_abs_loss 0.005911111831665039 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 27970 -> prob_abs_loss 0.005910396575927734 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 27980 -> prob_abs_loss 0.005910158157348633 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 27990 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 28000 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 8.0\n",
      "Epoch 28010 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 6.0\n",
      "Epoch 28020 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 2.0\n",
      "Epoch 28030 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 3.0\n",
      "Epoch 28040 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28050 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 4.0\n",
      "Epoch 28060 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28070 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28080 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 7.0\n",
      "Epoch 28090 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28100 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 3.0\n",
      "Epoch 28110 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28120 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 5.0\n",
      "Epoch 28130 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 1.0\n",
      "Epoch 28140 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 2.0\n",
      "Epoch 28150 -> prob_abs_loss 0.005910038948059082 | sampled_mse_loss 3.0\n",
      "Epoch 28160 -> prob_abs_loss 0.005885958671569824 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 28170 -> prob_abs_loss 0.005878567695617676 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 28180 -> prob_abs_loss 0.00587618350982666 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 28190 -> prob_abs_loss 0.005875349044799805 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 28200 -> prob_abs_loss 0.005874991416931152 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 28210 -> prob_abs_loss 0.005874991416931152 | sampled_mse_loss 0.0\n",
      "Epoch 28220 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 28230 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 1.0\n",
      "Epoch 28240 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 7.0\n",
      "Epoch 28250 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 7.0\n",
      "Epoch 28260 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28270 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28280 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28290 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 4.0\n",
      "Epoch 28300 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28310 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 5.0\n",
      "Epoch 28320 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 3.0\n",
      "Epoch 28330 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 6.0\n",
      "Epoch 28340 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 3.0\n",
      "Epoch 28350 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 7.0\n",
      "Epoch 28360 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28370 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 6.0\n",
      "Epoch 28380 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 2.0\n",
      "Epoch 28390 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 5.0\n",
      "Epoch 28400 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 5.0\n",
      "Epoch 28410 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 7.0\n",
      "Epoch 28420 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 4.0\n",
      "Epoch 28430 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 5.0\n",
      "Epoch 28440 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 5.0\n",
      "Epoch 28450 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 6.0\n",
      "Epoch 28460 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 3.0\n",
      "Epoch 28470 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 4.0\n",
      "Epoch 28480 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 3.0\n",
      "Epoch 28490 -> prob_abs_loss 0.0058748722076416016 | sampled_mse_loss 3.0\n",
      "Epoch 28500 -> prob_abs_loss 0.005853533744812012 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28510 -> prob_abs_loss 0.005842447280883789 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28520 -> prob_abs_loss 0.005838751792907715 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28530 -> prob_abs_loss 0.005837559700012207 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 28540 -> prob_abs_loss 0.005837082862854004 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28550 -> prob_abs_loss 0.005836963653564453 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 28560 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28570 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 1.0\n",
      "Epoch 28580 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 3.0\n",
      "Epoch 28590 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 7.0\n",
      "Epoch 28600 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 7.0\n",
      "Epoch 28610 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n",
      "Epoch 28620 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n",
      "Epoch 28630 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 6.0\n",
      "Epoch 28640 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 2.0\n",
      "Epoch 28650 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n",
      "Epoch 28660 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 3.0\n",
      "Epoch 28670 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 3.0\n",
      "Epoch 28680 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 10.0\n",
      "Epoch 28690 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 3.0\n",
      "Epoch 28700 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 2.0\n",
      "Epoch 28710 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 1.0\n",
      "Epoch 28720 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 7.0\n",
      "Epoch 28730 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n",
      "Epoch 28740 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n",
      "Epoch 28750 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 5.0\n",
      "Epoch 28760 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28770 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 9.0\n",
      "Epoch 28780 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 5.0\n",
      "Epoch 28790 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 7.0\n",
      "Epoch 28800 -> prob_abs_loss 0.005836844444274902 | sampled_mse_loss 3.0\n",
      "Epoch 28810 -> prob_abs_loss 0.005830168724060059 | sampled_mse_loss 7.0\n",
      "Model saved\n",
      "Epoch 28820 -> prob_abs_loss 0.00582277774810791 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28830 -> prob_abs_loss 0.0058203935623168945 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 28840 -> prob_abs_loss 0.005819559097290039 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 28850 -> prob_abs_loss 0.0058193206787109375 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28860 -> prob_abs_loss 0.005819201469421387 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 28870 -> prob_abs_loss 0.005819201469421387 | sampled_mse_loss 3.0\n",
      "Epoch 28880 -> prob_abs_loss 0.005819201469421387 | sampled_mse_loss 2.0\n",
      "Epoch 28890 -> prob_abs_loss 0.005790412425994873 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 28900 -> prob_abs_loss 0.005775272846221924 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 28910 -> prob_abs_loss 0.005770266056060791 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 28920 -> prob_abs_loss 0.00576859712600708 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 28930 -> prob_abs_loss 0.005768001079559326 | sampled_mse_loss 9.0\n",
      "Model saved\n",
      "Epoch 28940 -> prob_abs_loss 0.005767762660980225 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 28950 -> prob_abs_loss 0.005767762660980225 | sampled_mse_loss 5.0\n",
      "Epoch 28960 -> prob_abs_loss 0.005767762660980225 | sampled_mse_loss 4.0\n",
      "Epoch 28970 -> prob_abs_loss 0.005767762660980225 | sampled_mse_loss 2.0\n",
      "Epoch 28980 -> prob_abs_loss 0.005767762660980225 | sampled_mse_loss 4.0\n",
      "Epoch 28990 -> prob_abs_loss 0.005762279033660889 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 29000 -> prob_abs_loss 0.005733132362365723 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29010 -> prob_abs_loss 0.005724191665649414 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 29020 -> prob_abs_loss 0.005721092224121094 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 29030 -> prob_abs_loss 0.0057201385498046875 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 29040 -> prob_abs_loss 0.005719780921936035 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 29050 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29060 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 2.0\n",
      "Epoch 29070 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 4.0\n",
      "Epoch 29080 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 5.0\n",
      "Epoch 29090 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 2.0\n",
      "Epoch 29100 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 2.0\n",
      "Epoch 29110 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 2.0\n",
      "Epoch 29120 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 7.0\n",
      "Epoch 29130 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 4.0\n",
      "Epoch 29140 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 6.0\n",
      "Epoch 29150 -> prob_abs_loss 0.005719542503356934 | sampled_mse_loss 4.0\n",
      "Epoch 29160 -> prob_abs_loss 0.005701780319213867 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 29170 -> prob_abs_loss 0.00568699836730957 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 29180 -> prob_abs_loss 0.005682229995727539 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 29190 -> prob_abs_loss 0.005680561065673828 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 29200 -> prob_abs_loss 0.005680084228515625 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 29210 -> prob_abs_loss 0.0056798458099365234 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29220 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 0.0\n",
      "Model saved\n",
      "Epoch 29230 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 6.0\n",
      "Epoch 29240 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 8.0\n",
      "Epoch 29250 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29260 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29270 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 5.0\n",
      "Epoch 29280 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 8.0\n",
      "Epoch 29290 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 5.0\n",
      "Epoch 29300 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 7.0\n",
      "Epoch 29310 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 4.0\n",
      "Epoch 29320 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 6.0\n",
      "Epoch 29330 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 2.0\n",
      "Epoch 29340 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 2.0\n",
      "Epoch 29350 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29360 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 4.0\n",
      "Epoch 29370 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 4.0\n",
      "Epoch 29380 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29390 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 5.0\n",
      "Epoch 29400 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 0.0\n",
      "Epoch 29410 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 2.0\n",
      "Epoch 29420 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 7.0\n",
      "Epoch 29430 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29440 -> prob_abs_loss 0.005679726600646973 | sampled_mse_loss 3.0\n",
      "Epoch 29450 -> prob_abs_loss 0.00566864013671875 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 29460 -> prob_abs_loss 0.005610525608062744 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 29470 -> prob_abs_loss 0.005592525005340576 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29480 -> prob_abs_loss 0.005586564540863037 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 29490 -> prob_abs_loss 0.005584418773651123 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 29500 -> prob_abs_loss 0.005583703517913818 | sampled_mse_loss 4.0\n",
      "Model saved\n",
      "Epoch 29510 -> prob_abs_loss 0.005583465099334717 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29520 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 29530 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29540 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 6.0\n",
      "Epoch 29550 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Epoch 29560 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29570 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 6.0\n",
      "Epoch 29580 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Epoch 29590 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29600 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29610 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Epoch 29620 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 5.0\n",
      "Epoch 29630 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29640 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 0.0\n",
      "Epoch 29650 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 7.0\n",
      "Epoch 29660 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 3.0\n",
      "Epoch 29670 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 9.0\n",
      "Epoch 29680 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29690 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29700 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 6.0\n",
      "Epoch 29710 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29720 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 5.0\n",
      "Epoch 29730 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29740 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29750 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 5.0\n",
      "Epoch 29760 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 9.0\n",
      "Epoch 29770 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 5.0\n",
      "Epoch 29780 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 9.0\n",
      "Epoch 29790 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 0.0\n",
      "Epoch 29800 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Epoch 29810 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 3.0\n",
      "Epoch 29820 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 3.0\n",
      "Epoch 29830 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 2.0\n",
      "Epoch 29840 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29850 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29860 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 3.0\n",
      "Epoch 29870 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 5.0\n",
      "Epoch 29880 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 9.0\n",
      "Epoch 29890 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 1.0\n",
      "Epoch 29900 -> prob_abs_loss 0.005583345890045166 | sampled_mse_loss 4.0\n",
      "Epoch 29910 -> prob_abs_loss 0.005564868450164795 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 29920 -> prob_abs_loss 0.005549490451812744 | sampled_mse_loss 8.0\n",
      "Model saved\n",
      "Epoch 29930 -> prob_abs_loss 0.005544602870941162 | sampled_mse_loss 6.0\n",
      "Model saved\n",
      "Epoch 29940 -> prob_abs_loss 0.005542933940887451 | sampled_mse_loss 3.0\n",
      "Model saved\n",
      "Epoch 29950 -> prob_abs_loss 0.005542337894439697 | sampled_mse_loss 5.0\n",
      "Model saved\n",
      "Epoch 29960 -> prob_abs_loss 0.005542099475860596 | sampled_mse_loss 2.0\n",
      "Model saved\n",
      "Epoch 29970 -> prob_abs_loss 0.005542099475860596 | sampled_mse_loss 6.0\n",
      "Epoch 29980 -> prob_abs_loss 0.005541980266571045 | sampled_mse_loss 1.0\n",
      "Model saved\n",
      "Epoch 29990 -> prob_abs_loss 0.005541980266571045 | sampled_mse_loss 8.0\n"
     ]
    }
   ],
   "source": [
    "model, losses, sampled_mse_losses = train(model,\n",
    "                                          true_dag_adj=true_dag_adj,\n",
    "                                          max_epochs=30000,\n",
    "                                          patience=100\n",
    "                                         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:differentiable-dag-sampling] *",
   "language": "python",
   "name": "conda-env-differentiable-dag-sampling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
